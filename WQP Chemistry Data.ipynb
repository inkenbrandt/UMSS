{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from numpy import dtype\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams, rc\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "#from __future__ import unicode_literals\n",
    "\n",
    "#%matplotlib inline\n",
    "#rcParams['figure.figsize'] = 15, 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOGM Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utah Division of Oil Gas and Mining (DOGM) data derived from the <a href=http://linux1.ogm.utah.gov/WebStuff/wwwroot/wqdb.html>DOGM website</a>. Station information obtained from digitization of PDF maps provided by mining companies to DOGM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ubuntu rootname = \"/media/p/5F5B-8FCB/PROJECTS/MLSNF/Data/CHEM/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rootname = \"E:/PROJECTS/MLSNF/Data/CHEM/\"\n",
    "rootname = \"U:/GWP/Groundwater/UMSS_Manti/Data/\"\n",
    "#rootname = \"/media/p/5F5B-8FCB/PROJECTS/MLSNF/Data/CHEM/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOGM = rootname + \"DOGM/UDOGM_allResults.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOGM_ST = rootname + \"DOGM/dogm_stations.xls\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and Prepare DOGM Results Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parmatch = {\"ACIDITY AS CACO3\":\"Acidity\", \"TOTAL ALKALINITY AS CACO3\":\"Alkalinity, total\", \n",
    "            \"DISSOLVED ALUMINUM\":\"Aluminum\", \"TOTAL ALUMINUM\":\"Aluminum\", \"AMMONIA AS N\":\"Ammonia-nitrogen as N\", \n",
    "            \"DISSOLVED ARSENIC\":\"Arsenic\", \"TOTAL ARSENIC\":\"Arsenic\", \"DISSOLVED BARIUM\":\"Barium\", \n",
    "            \"TOTAL BARIUM\":\"Barium\", \"TOTAL BERYLLIUM\":\"Beryllium\", \"BICARBONATE AS HCO3\":\"Bicarbonate\", \n",
    "            \"B.O.D. 5, MG/L\":\"Biochemical oxygen demand, standard conditions\", \"DISSOLVED BORON\":\"Boron\", \n",
    "            \"TOTAL BORON\":\"Boron\", \"BROMIDE\":\"Bromide\", \"DISSOLVED CADMIUM\":\"Cadmium\", \"TOTAL CADMIUM\":\"Cadmium\", \n",
    "            \"DISSOLVED CALCIUM\":\"Calcium\", \"TOTAL CALCIUM\":\"Calcium\", \"CARBONATE AS CO3\":\"Carbonate\", \n",
    "            \"C.O.D., MG/L\":\"Chemical oxygen demand\", \"CHLORIDE\":\"Chloride\", \"DISSOLVED CHROMIUM\":\"Chromium\", \n",
    "            \"TOTAL CHROMIUM\":\"Chromium\", \"CHROMIUM HEX, CR\":\"Chromium(VI)\", \"TOTAL COBALT\":\"Cobalt\", \n",
    "            \"SP. CONDUCTIVITY (FIELD)\":\"Conductivity\", \"SPECIFIC CONDUCTIVITY (LAB)\":\"Conductivity\", \n",
    "            \"DISSOLVED COPPER\":\"Copper\", \"TOTAL COPPER\":\"Copper\", \"CYANIDE\":\"Cyanide\", \"DEPTH\":\"Depth\", \n",
    "            \"DISSOLVED OXYGEN (FIELD)\":\"Dissolved oxygen (DO)\", \"FLOW\":\"Flow\", \"FLUORIDE\":\"Fluoride\", \n",
    "            \"TOTAL HARDNESS AS CACO3\":\"Hardness, Ca, Mg\", \"HYDROXIDE\":\"Hydroxide\", \"DISSOLVED IRON\":\"Iron\", \n",
    "            \"TOTAL IRON\":\"Iron\", \"TOTAL KIELDAHL NITROGEN, T.K.N.\":\"Kjeldahl nitrogen\", \"DISSOLVED LEAD\":\"Lead\", \n",
    "            \"TOTAL LEAD\":\"Lead\", \"DISSOLVED MAGNESIUM\":\"Magnesium\", \"TOTAL MAGNESIUM\":\"Magnesium\", \n",
    "            \"DISSOLVED MANGANESE\":\"Manganese\", \"TOTAL MANGANESE\":\"Manganese\", \"DISSOLVED MERCURY\":\"Mercury\", \n",
    "            \"TOTAL MERCURY\":\"Mercury\", \"DISSOLVED MOLYBDENUM\":\"Molybdenum\", \"TOTAL MOLYBDENUM\":\"Molybdenum\", \n",
    "            \"DISSOLVED NICKEL\":\"Nickel\", \"TOTAL NICKEL\":\"Nickel\", \"DISSOLVED NITRATE, NO3\":\"Nitrate\", \n",
    "            \"NITRATE AS N\":\"Nitrate as N\", \"DISSOLVED NITRITE, NO2\":\"Nitrite\", \"NITRITE AS N\":\"Nitrogen\", \n",
    "            \"NO2+NO3 AS N\":\"Nitrogen\", \"DISSOLVED ORTHO PHOSPH, OPO4\":\"Orthophosphate\", \n",
    "            \"ORTHO. PHOSPHATE\":\"Orthophosphate\", \"PH (FIELD)\":\"pH\", \"PH (LAB)\":\"pH, lab\", \n",
    "            \"TOTAL PHOSPHORUS\":\"Phosphorus\", \"DISSOLVED POTASSIUM\":\"Potassium\", \"DISSOLVED SELENIUM\":\"Selenium\", \n",
    "            \"TOTAL SELENIUM\":\"Selenium\", \"DISSOLVED SILICA, SIO2\":\"Silica\", \"DISSOLVED SILVER\":\"Silver\", \n",
    "            \"TOTAL SILVER\":\"Silver\", \"DISSOLVED SODIUM\":\"Sodium\", \"TOTAL SODIUM\":\"Sodium\", \n",
    "            \"SODIUM ADSORPTION RATIO\":\"Sodium adsorption ratio\", \"SULFATE\":\"Sulfate\", \"SULFIDE\":\"Sulfide\", \n",
    "            \"TOTAL ANIONS\":\"Sum of anions\", \"TOTAL CATIONS\":\"Sum of cations\", \n",
    "            \"AIR TEMPERATURE (FIELD)\":\"Temperature, air\", \"FIELD WATER TEMPERATURE\":\"Temperature, water\", \n",
    "            \"TOTAL DISSOLVED SOLIDS, @ 180 C\":\"Total dissolved solids\", \n",
    "            \"TOTAL SUSPENDED SOLIDS\":\"Total suspended solids\", \"TURBIDITY (FIELD)\":\"Turbidity\", \n",
    "            \"TURBIDITY (LAB)\":\"Turbidity\", \"TOTAL VANADIUM\":\"Vanadium\", \"DISSOLVED ZINC\":\"Zinc\", \"TOTAL ZINC\":\"Zinc\"} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dogtypes = {'Unnamed: 0':dtype('int8'),'MIN_DET': dtype('float32'), 'MINE_ID': dtype('int8'), \n",
    "            'ANAL_NAME': dtype('str_'), 'PARAM_ID': dtype('int8'), 'SAMPLE_ID': dtype('str_'), 'SITE_NAME': dtype('str_'), \n",
    "            'METHD': dtype('str_'), 'DATE_REC': dtype('str_'),'EQUALITY': dtype('str_'), 'TIME_ANAL': dtype('str_'), \n",
    "            'STATION_ID': dtype('str_'), 'PAR_DESC': dtype('str_'), 'PAR_ABB': dtype('str_'), 'ANAL_METHD': dtype('str_'), \n",
    "            'METH_DESC': dtype('str_'), 'SAMP_TYPE': dtype('str_'), 'LAB_ID': dtype('str_'), 'MINE_NAME': dtype('str_'), \n",
    "            'SITE_DESC': dtype('str_'), 'SITE_ID': dtype('int8'), 'VALUE': dtype('float32'), 'PERM_NO': dtype('str_'), \n",
    "            'LAB_NAME': dtype('str_'), 'UNITS': dtype('str_'), 'SAMP_DESC': dtype('str_'), 'DATE_ANAL': dtype('str_'), \n",
    "            'SITE_TYPE': dtype('str_'), 'LAB_CODE': dtype('str_'), 'SAMPLR_NAM': dtype('str_'), 'COMMENTS': dtype('str_')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dogmr = pd.read_csv(DOGM, dtype=dogtypes, parse_dates=[11,14,15,19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DResCols = {\"ANAL_METHD\":\"AnalytMeth\", \"ANAL_NAME\":\"Param\", \"COMMENTS\":\"ResultComment\", \"DATE_ANAL\":\"AnalysisDate\", \n",
    "            \"DATETIME_SAMP\":\"SampleDate\", \"EQUALITY\":\"DetectCond\", \"LAB_CODE\":\"LabComments\", \"LAB_NAME\":\"LabName\", \n",
    "            \"METH_DESC\":\"MethodDescript\", \"METHD\":\"SampMeth\", \"MIN_DET\":\"MDL\", \"SAMP_TYPE\":\"SampMethName\", \n",
    "            \"SAMPLE_ID\":\"SampleId\", \"STATION_ID\":\"StationId\", \"UNITS\":\"Unit\", \"VALUE\":\"ResultValue\"} \n",
    "dogmr.rename(columns=DResCols,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dogmr['Param'] = dogmr['PAR_DESC'].apply(lambda x: parmatch.get(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dogmr.dropna(how='any',subset=['StationId'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dogmr.drop(['PARAM_ID','SAMPLR_NAM','SITE_ID','SITE_DESC','PAR_DESC','TIME_ANAL','DATE_RPT',\n",
    "            'DATE_REC','Unnamed: 0', 'LAB_ID','MINE_ID','PAR_ABB','MINE_NAME', 'SITE_NAME', 'SAMP_DESC',\n",
    "            'PERM_NO','SITE_TYPE'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'LabComments', u'DetectCond', u'ResultValue', u'Unit', u'MDL',\n",
       "       u'AnalytMeth', u'AnalysisDate', u'Param', u'SampMethName',\n",
       "       u'ResultComment', u'SampleDate', u'SampMeth', u'MethodDescript',\n",
       "       u'LabName', u'SampleId', u'StationId'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogmr.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Import and Prepare DOGM Station Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dogms = pd.read_excel(DOGM_ST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consolidate descriptor columns into `StationComment` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##WQP Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data downloaded from the <a href=http://waterqualitydata.us/portal/>Water Quality Portal (WQP)</a> on 7/22/2015. <br>\n",
    "<b>Stations:</b><br>\n",
    "http://waterqualitydata.us/Station/search?sampleMedia=Water&characteristicType=Information%3BInorganics%2C+Major%2C+Metals%3BInorganics%2C+Major%2C+Non-metals%3BInorganics%2C+Minor%2C+Metals%3BInorganics%2C+Minor%2C+Non-metals%3BNot+Assigned%3BNutrient%3BPhysical%3BStable+Isotopes&bBox=-111.68%2C38.8%2C-111%2C40&mimeType=csv&zip=yes&sorted=no <br>\n",
    "<b>Results:</b><br>\n",
    "http://waterqualitydata.us/Result/search?sampleMedia=Water&characteristicType=Information%3BInorganics%2C+Major%2C+Metals%3BInorganics%2C+Major%2C+Non-metals%3BInorganics%2C+Minor%2C+Metals%3BInorganics%2C+Minor%2C+Non-metals%3BNot+Assigned%3BNutrient%3BPhysical%3BStable+Isotopes&bBox=-111.68%2C38.8%2C-111%2C40&mimeType=csv&zip=yes&sorted=no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define location of data downloaded from the Water Quality Portal site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = rootname +\"WQP/Result.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Results Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map data types for data to be imported and designate columns to convert to datetimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rdtypes = {\"OrganizationIdentifier\":np.str_, \"OrganizationFormalName\":np.str_, \"ActivityIdentifier\":np.str_, \n",
    "           \"ActivityTypeCode\":np.str_, \"ActivityMediaName\":np.str_, \"ActivityMediaSubdivisionName\":np.str_, \n",
    "           \"ActivityStartDate\":np.str_, \"ActivityStartTime/Time\":np.str_, \"ActivityStartTime/TimeZoneCode\":np.str_, \n",
    "           \"ActivityEndDate\":np.str_, \"ActivityEndTime/Time\":np.str_, \"ActivityEndTime/TimeZoneCode\":np.str_, \n",
    "           \"ActivityDepthHeightMeasure/MeasureValue\":np.float16, \"ActivityDepthHeightMeasure/MeasureUnitCode\":np.str_, \n",
    "           \"ActivityDepthAltitudeReferencePointText\":np.str_, \"ActivityTopDepthHeightMeasure/MeasureValue\":np.float16, \n",
    "           \"ActivityTopDepthHeightMeasure/MeasureUnitCode\":np.str_, \n",
    "           \"ActivityBottomDepthHeightMeasure/MeasureValue\":np.float16, \n",
    "           \"ActivityBottomDepthHeightMeasure/MeasureUnitCode\":np.str_, \n",
    "           \"ProjectIdentifier\":np.str_, \"ActivityConductingOrganizationText\":np.str_, \n",
    "           \"MonitoringLocationIdentifier\":np.str_, \"ActivityCommentText\":np.str_, \n",
    "           \"SampleAquifer\":np.str_, \"HydrologicCondition\":np.str_, \"HydrologicEvent\":np.str_, \n",
    "           \"SampleCollectionMethod/MethodIdentifier\":np.str_, \"SampleCollectionMethod/MethodIdentifierContext\":np.str_, \n",
    "           \"SampleCollectionMethod/MethodName\":np.str_, \"SampleCollectionEquipmentName\":np.str_, \n",
    "           \"ResultDetectionConditionText\":np.str_, \"CharacteristicName\":np.str_, \"ResultSampleFractionText\":np.str_, \n",
    "           \"ResultMeasureValue\":np.str_, \"ResultMeasure/MeasureUnitCode\":np.str_, \"MeasureQualifierCode\":np.str_, \n",
    "           \"ResultStatusIdentifier\":np.str_, \"StatisticalBaseCode\":np.str_, \"ResultValueTypeName\":np.str_, \n",
    "           \"ResultWeightBasisText\":np.str_, \"ResultTimeBasisText\":np.str_, \"ResultTemperatureBasisText\":np.str_, \n",
    "           \"ResultParticleSizeBasisText\":np.str_, \"PrecisionValue\":np.str_, \"ResultCommentText\":np.str_, \n",
    "           \"USGSPCode\":np.str_, \"ResultDepthHeightMeasure/MeasureValue\":np.float16, \n",
    "           \"ResultDepthHeightMeasure/MeasureUnitCode\":np.str_, \"ResultDepthAltitudeReferencePointText\":np.str_, \n",
    "           \"SubjectTaxonomicName\":np.str_, \"SampleTissueAnatomyName\":np.str_, \n",
    "           \"ResultAnalyticalMethod/MethodIdentifier\":np.str_, \"ResultAnalyticalMethod/MethodIdentifierContext\":np.str_, \n",
    "           \"ResultAnalyticalMethod/MethodName\":np.str_, \"MethodDescriptionText\":np.str_, \"LaboratoryName\":np.str_, \n",
    "           \"AnalysisStartDate\":np.str_, \"ResultLaboratoryCommentText\":np.str_, \n",
    "           \"DetectionQuantitationLimitTypeName\":np.str_, \"DetectionQuantitationLimitMeasure/MeasureValue\":np.str_, \n",
    "           \"DetectionQuantitationLimitMeasure/MeasureUnitCode\":np.str_, \"PreparationStartDate\":np.str_, \n",
    "           \"ProviderName\":np.str_} \n",
    "\n",
    "dt = [[6,7],56,61]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import result data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = pd.read_csv(result, dtype=Rdtypes, parse_dates=dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(list(res['CharacteristicName'].unique())).to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remap column names to standards and drop unneeded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ResFieldDict = {\"AnalysisStartDate\":\"AnalysisDate\", \"ResultAnalyticalMethod/MethodIdentifier\":\"AnalytMeth\", \n",
    "                \"ResultAnalyticalMethod/MethodName\":\"AnalytMethId\", \"ResultDetectionConditionText\":\"DetectCond\", \n",
    "                \"ResultLaboratoryCommentText\":\"LabComments\", \"LaboratoryName\":\"LabName\", \n",
    "                \"DetectionQuantitationLimitTypeName\":\"LimitType\", \"DetectionQuantitationLimitMeasure/MeasureValue\":\"MDL\", \n",
    "                \"DetectionQuantitationLimitMeasure/MeasureUnitCode\":\"MDLUnit\", \"MethodDescriptionText\":\"MethodDescript\", \n",
    "                \"OrganizationIdentifier\":\"OrgId\", \"OrganizationFormalName\":\"OrgName\", \"CharacteristicName\":\"Param\", \n",
    "                \"ProjectIdentifier\":\"ProjectId\", \"MeasureQualifierCode\":\"QualCode\", \"ResultCommentText\":\"ResultComment\", \n",
    "                \"ResultStatusIdentifier\":\"ResultStatus\", \"ResultMeasureValue\":\"ResultValue\", \n",
    "                \"ActivityCommentText\":\"SampComment\", \"ActivityDepthHeightMeasure/MeasureValue\":\"SampDepth\", \n",
    "                \"ActivityDepthAltitudeReferencePointText\":\"SampDepthRef\", \n",
    "                \"ActivityDepthHeightMeasure/MeasureUnitCode\":\"SampDepthU\", \"SampleCollectionEquipmentName\":\"SampEquip\", \n",
    "                \"ResultSampleFractionText\":\"SampFrac\", \"ActivityStartDate\":\"SampleDate\", \"ActivityIdentifier\":\"SampleId\", \n",
    "                \"ActivityStartTime/Time\":\"SampleTime\", \"ActivityMediaSubdivisionName\":\"SampMedia\", \n",
    "                \"SampleCollectionMethod/MethodIdentifier\":\"SampMeth\", \"SampleCollectionMethod/MethodName\":\"SampMethName\", \n",
    "                \"ActivityTypeCode\":\"SampType\", \"MonitoringLocationIdentifier\":\"StationId\", \n",
    "                \"ResultMeasure/MeasureUnitCode\":\"Unit\", \"USGSPCode\":\"USGSPCode\",\n",
    "                \"ActivityStartDate_ActivityStartTime/Time\":\"SampleDate\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res.rename(columns=ResFieldDict,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resdroplist = [\"ActivityBottomDepthHeightMeasure/MeasureUnitCode\", \"ActivityBottomDepthHeightMeasure/MeasureValue\", \n",
    "               \"ActivityConductingOrganizationText\", \"ActivityEndDate\", \"ActivityEndTime/Time\", \n",
    "               \"ActivityEndTime/TimeZoneCode\", \"ActivityMediaName\", \"ActivityStartTime/TimeZoneCode\", \n",
    "               \"ActivityTopDepthHeightMeasure/MeasureUnitCode\", \"ActivityTopDepthHeightMeasure/MeasureValue\", \n",
    "               \"HydrologicCondition\", \"HydrologicEvent\", \"PrecisionValue\", \"PreparationStartDate\", \"ProviderName\", \n",
    "               \"ResultAnalyticalMethod/MethodIdentifierContext\", \"ResultDepthAltitudeReferencePointText\", \n",
    "               \"ResultDepthHeightMeasure/MeasureUnitCode\", \"ResultDepthHeightMeasure/MeasureValue\", \n",
    "               \"ResultParticleSizeBasisText\", \"ResultTemperatureBasisText\", \n",
    "               \"ResultTimeBasisText\", \"ResultValueTypeName\", \"ResultWeightBasisText\", \"SampleAquifer\", \n",
    "               \"SampleCollectionMethod/MethodIdentifierContext\", \"SampleTissueAnatomyName\", \"StatisticalBaseCode\", \n",
    "               \"SubjectTaxonomicName\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res.drop(resdroplist,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert string fields to values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res['ResultValue'] = res['ResultValue'].convert_objects(convert_numeric=True)\n",
    "res['MDL'] = res['MDL'].convert_objects(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `_WQX` suffix from `StationID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res['StationId'] = res['StationId'].str.replace('_WQX-','-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Station Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stat = pd.read_csv(station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map Fields to Standard UGS database format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "StatFieldDict = {\"MonitoringLocationIdentifier\":\"StationId\", \"AquiferName\":\"Aquifer\", \"AquiferTypeName\":\"AquiferType\", \n",
    "             \"ConstructionDateText\":\"ConstDate\", \"CountyCode\":\"CountyCode\", \"WellDepthMeasure/MeasureValue\":\"Depth\", \n",
    "             \"WellDepthMeasure/MeasureUnitCode\":\"DepthUnit\", \"VerticalMeasure/MeasureValue\":\"Elev\", \n",
    "             \"VerticalAccuracyMeasure/MeasureValue\":\"ElevAcc\", \"VerticalAccuracyMeasure/MeasureUnitCode\":\"ElevAccUnit\", \n",
    "             \"VerticalCollectionMethodName\":\"ElevMeth\", \"VerticalCoordinateReferenceSystemDatumName\":\"ElevRef\", \n",
    "             \"VerticalMeasure/MeasureUnitCode\":\"ElevUnit\", \"FormationTypeText\":\"FmType\", \n",
    "             \"WellHoleDepthMeasure/MeasureValue\":\"HoleDepth\", \"WellHoleDepthMeasure/MeasureUnitCode\":\"HoleDUnit\", \n",
    "             \"HorizontalAccuracyMeasure/MeasureValue\":\"HorAcc\", \"HorizontalAccuracyMeasure/MeasureUnitCode\":\"HorAccUnit\", \n",
    "             \"HorizontalCollectionMethodName\":\"HorCollMeth\", \"HorizontalCoordinateReferenceSystemDatumName\":\"HorRef\", \n",
    "             \"HUCEightDigitCode\":\"HUC8\", \"LatitudeMeasure\":\"Lat_Y\", \"LongitudeMeasure\":\"Lon_X\", \n",
    "             \"OrganizationIdentifier\":\"OrgId\", \"OrganizationFormalName\":\"OrgName\", \"StateCode\":\"StateCode\", \n",
    "             \"MonitoringLocationDescriptionText\":\"StationComment\", \"MonitoringLocationName\":\"StationName\", \n",
    "             \"MonitoringLocationTypeName\":\"StationType\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stat.rename(columns=StatFieldDict,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop leftover fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statdroplist = [\"ContributingDrainageAreaMeasure/MeasureUnitCode\", \"ContributingDrainageAreaMeasure/MeasureValue\", \n",
    "                \"DrainageAreaMeasure/MeasureUnitCode\", \"DrainageAreaMeasure/MeasureValue\", \"CountryCode\", \"ProviderName\", \n",
    "                \"SourceMapScaleNumeric\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stat.drop(statdroplist,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `_WQX` suffix from `StationID` and take out duplicate stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stat['StationId'] = stat['StationId'].str.replace('_WQX-','-')\n",
    "stat.drop_duplicates(subset=['StationId'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Combine Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append Results Data Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.concat([res,dogmr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del(res,dogmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ParAbb = {\"Alkalinity\":\"Alk\", \"Alkalinity, Carbonate as CaCO3\":\"Alk\", \"Alkalinity, total\":\"Alk\", \n",
    "          \"Arsenic\":\"As\", \"Calcium\":\"Ca\", \"Chloride\":\"Cl\", \"Carbon dioxide\":\"CO2\", \"Carbonate\":\"CO3\", \n",
    "          \"Carbonate (CO3)\":\"CO3\", \"Specific conductance\":\"Cond\", \"Conductivity\":\"Cond\", \"Copper\":\"Cu\", \n",
    "          \"Depth\":\"Depth\", \"Dissolved oxygen (DO)\":\"DO\", \"Iron\":\"Fe\", \n",
    "          \"Hardness, Ca, Mg\":\"Hard\", \"Total hardness -- SDWA NPDWR\":\"Hard\", \n",
    "          \"Bicarbonate\":\"HCO3\", \"Potassium\":\"K\", \"Magnesium\":\"Mg\", \"Kjeldahl nitrogen\":\"N\", \n",
    "          \"Nitrogen, mixed forms (NH3), (NH4), organic, (NO2) and (NO3)\":\"N\", \"Nitrogen\":\"N\", \"Sodium\":\"Na\", \n",
    "          \"Sodium plus potassium\":\"NaK\", \"Ammonia-nitrogen\":\"NH3_N\", \"Ammonia-nitrogen as N\":\"N\", \"Nitrite\":\"NO2\", \n",
    "          \"Nitrate\":\"NO3\", \"Nitrate as N\":\"N\", \"pH, lab\":\"pH\", \"pH\":\"pH\",  \"Phosphate-phosphorus\":\"PO4\", \n",
    "          \"Orthophosphate\":\"PO4\", \"Phosphate\":\"PO4\", \"Stream flow, instantaneous\":\"Q\", \"Flow\":\"Q\", \n",
    "          \"Flow rate, instantaneous\":\"Q\", \"Silica\":\"Si\", \"Sulfate\":\"SO4\", \"Sulfate as SO4\":\"SO4\", \n",
    "          \"Total dissolved solids\":\"TDS\", \"Temperature, water\":\"Temp\", \n",
    "          \"Total suspended solids\":\"TSS\", \"Turbidity\":\"Turb\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ParUnAbb = {'Alk':u'mg/L', 'As':u'\\u03BCg/L', 'Ca':u'mg/L', 'Cl':u'mg/L', 'CO2':u'mg/L', 'CO3':u'mg/L', 'Cond':u'\\u03BChoms/cm',\n",
    "           'Cu':u'\\u03BCg/L', 'DO':u'mg/L', 'Hard':u'mg/L', 'HCO3':u'mg/L', 'K':u'mg/L', 'Mg':u'mg/L', 'N':u'mg/L', 'pH':u'', \n",
    "            'Q':u'gpm', 'Fe':u'\\u03BCg/L', 'TDS':u'mg/L', 'Si':u'mg/L', 'SO4':u'mg/L', 'Temp':u'\\N{DEGREE SIGN}C', 'PO4':u'mg/L', 'TSS':u'mg/L',\n",
    "           'Turb':u'Turb. Units', 'Na':u'mg/L', 'NaK':u'mg/L', 'NO3':u'mg/L', 'NH3':u'mg/L', 'NO2':u'mg/L', 'NH3_N':u'mg/L'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results['ParAbb'] = results['Param'].apply(lambda x: ParAbb.get(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del results['USGSPCode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#results.to_csv(rootname+\"AllResults.csv\", chunksize=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dogms.set_index(['StationId'],inplace=True)\n",
    "station = dogms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station[\"index\"] = station.index\n",
    "station.drop_duplicates(subset='index', take_last=True, inplace=True)\n",
    "del station[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stattype = {\"Stream: Ditch\":\"Stream\", \"Stream\":\"Stream\", \"Well\":\"Well\", \"Spring\":\"Spring\", \n",
    "            \"Stream: Canal\":\"Stream\", \"Subsurface: Tunnel, shaft, or mine\":\"Mine Drain\", \n",
    "            \"Well: Test hole not completed as a well\":\"Well\", \"Subsurface: Groundwater drain\":\"Mine Drain\", \n",
    "            \"Lake, Reservoir, Impoundment\":\"Lake\", \"River/Stream\":\"Stream\", \"Lake\":\"Lake\", \"Facility Other\":\"Other\", \n",
    "            \"Canal Drainage\":\"Stream\", \"Canal Irrigation\":\"Stream\", \"MD\":\"Mine Drain\", \"SW\":\"Stream\", \"GW\":\"Well\", \n",
    "            \"SP\":\"Spring\", \"UPDES Permit discharge point\":\"Mine Drain\", \"Lake; Sediment Pond; Stagnant water\":\"Lake\", \n",
    "            \"Other\":\"Other\", \"CG-2\":\"Other\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "station['StationType'] = station['StationType'].apply(lambda x: stattype.get(x),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Summarize and Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['StationId', 'Param', 'amin', 'amax', 'size']\n"
     ]
    }
   ],
   "source": [
    "durationsummary = results.groupby(['StationId','Param'])['SampleDate'].agg([np.min,np.max,np.size]).reset_index()\n",
    "durationsummary.convert_objects(convert_numeric=True)\n",
    "print list(durationsummary.columns)\n",
    "durationsummary['amax'] =  durationsummary['amax'].apply(lambda x: str(x).replace('nan','00:00:00'),1)\n",
    "durationsummary['amin'] =  durationsummary['amin'].apply(lambda x: str(x).replace('nan','00:00:00'),1)\n",
    "durationsummary['duration'] = durationsummary['amax'].astype(np.datetime64) - durationsummary['amin'].astype(np.datetime64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "durationsummary.to_csv(rootname + \"fieldsummaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LongFlow = durationsummary[(durationsummary['Param']=='Flow') & (durationsummary['size']>50) & \n",
    "                           (durationsummary['duration']>365*10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LongFlowList = list(LongFlow['StationId'].values)\n",
    "FlowResGPM = results[(results['StationId'].isin(LongFlowList)) & (results['ResultValue'] != np.nan) & \n",
    "                     (results['Unit']=='GPM')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LongFlowList = list(LongFlow['StationId'].values)\n",
    "FlowResGPM = results[(results['StationId'].isin(LongFlowList)) & (results['ResultValue'] != np.nan) & \n",
    "                     (results['Unit']=='GPM')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FlowResGPM.reset_index(inplace=True)\n",
    "FlowResGPM.set_index('SampleDate',inplace=True)\n",
    "FlowResGPM.sort_index(inplace=True)\n",
    "FlowResGPM['pyDate'] = FlowResGPM.index.to_pydatetime()\n",
    "FlowResGPM['JulDate'] = FlowResGPM.index.to_julian_date()\n",
    "\n",
    "FlowResGPM = pd.merge(FlowResGPM, station, left_on='StationId', right_index=True, how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\ArcGIS10.3\\lib\\site-packages\\IPython\\kernel\\__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "pdf = PdfPages(rootname+'flowres.pdf')\n",
    "\n",
    "xmax = np.max(FlowResGPM['pyDate'].values)\n",
    "xmin = np.min(FlowResGPM['pyDate'].values)\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams.update({'font.size': 10})\n",
    "\n",
    "for key, grp in FlowResGPM.groupby(['StationId']):\n",
    "    if np.max(grp['ResultValue'])>0:\n",
    "        # determine gallons flowing for each time period\n",
    "        grp['Gallons'] = grp['ResultValue'] * grp['JulDate'].diff()*60*24*3.06888328E-6 \n",
    "        y2 = grp['Gallons'].cumsum().values\n",
    "        # filter out graphs smaller than 30 non-zero points\n",
    "        if np.count_nonzero(grp['ResultValue']) > 30:\n",
    "            fig = plt.figure(figsize=(10,8))\n",
    "            title = str(str(grp['StationName'].values[0]) + ' ' + str(grp['StationType'].values[0]))\n",
    "            if title == \"nan nan\":\n",
    "                plt.title(key)\n",
    "            else:\n",
    "                plt.title(title)\n",
    "\n",
    "            ax = fig.add_subplot(111)\n",
    "            ax.plot(grp['pyDate'].values,grp['ResultValue'].values, label='Discharge', linestyle='-', marker='.', color='b')\n",
    "            ax.set_ylabel('Discharge (gpm)')\n",
    "            ax.set_xlabel('Date')\n",
    "            ax.set_xlim([xmin,xmax])\n",
    "\n",
    "            ax2 = ax.twinx()\n",
    "            ax2.plot(grp['pyDate'].values, y2, label='Cumulative Discharge', linestyle='--', color='g')\n",
    "            ax2.set_ylabel('Cumulative Discharge (ac-ft)')\n",
    "\n",
    "\n",
    "            # ask matplotlib for the plotted objects and their labels\n",
    "            lines, labels = ax.get_legend_handles_labels()\n",
    "            lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "            ax2.legend(lines + lines2, labels + labels2, loc='upper left', bbox_to_anchor=(-0.10, 1.15))\n",
    "            ax2.set_xlim([xmin,xmax])\n",
    "            #plt.tight_layout()\n",
    "            pdf.savefig(fig)\n",
    "            plt.close()\n",
    "    \n",
    "\n",
    "\n",
    "d = pdf.infodict()\n",
    "d['Title'] = 'Discharge Data'\n",
    "d['Author'] = u'Paul Inkenbrandt'\n",
    "d['Subject'] = 'Discharge Data from Manti LaSal'\n",
    "d['Keywords'] = 'PdfPages multipage keywords author title subject'\n",
    "d['CreationDate'] = datetime.datetime.today()\n",
    "d['ModDate'] = datetime.datetime.today()\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Pivot Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows from the `results` table that have null `SampleId` values or parameter abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.dropna(subset=['SampleId','ParAbb'],how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows from the `results` table that have a detection condition (ex. \"not detected\").  This eliminates nondetects, which will inhereantly bias the data, as it is not considering values below the detection levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = results[pd.isnull(results['DetectCond'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows from the `results` table that have duplicate `SampleId` values and parameters (chemical concentrations, field measurements). The `SampleId` field will be the index for the pivoted table.  Each row in the pivoted table will represent an individual water sample.  The `SampleId` is applied to each parameter that comes from the same water sample.  For example, if I go out to a stream and fill a water bottle and have that analyzed for 4 different parameters (i.e. calcium, magnesium, sodium, and chloride), then each result from the analysis of that water will have the same `SampleId`.  Sometimes we sample a station multiple times, so one `StationId` can have many `SampleId` values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.drop_duplicates(subset=['SampleId','ParAbb'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select results that have more than 50 flow values to plot flow change over time.\n",
    "http://stackoverflow.com/questions/17926273/how-to-count-distinct-values-in-a-column-of-a-pandas-group-by-object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def condfix(x):\n",
    "    if x[1]=='Cond':\n",
    "        if x[2]=='mS/cm':\n",
    "            return x[0]/1000\n",
    "        else:\n",
    "            return x[0]\n",
    "    else:\n",
    "        return x[0]\n",
    "    \n",
    "def condunitfix(x):\n",
    "    if x[1]=='Cond':\n",
    "        if x[0]=='mS/cm':\n",
    "            return 'uS/cm'\n",
    "        else:\n",
    "            return 'uS/cm'\n",
    "    else:\n",
    "        return x[0]\n",
    "\n",
    "def pHfix(x):\n",
    "    if x[1] == 'pH':\n",
    "        if x[0] == 0.0:\n",
    "            return np.nan\n",
    "        elif x[0] >= 14.0:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return x[0]\n",
    "    else:\n",
    "        return x[0]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results['ResultValue'] = results[['ResultValue','ParAbb','Unit']].apply(lambda x: condfix(x),1)\n",
    "results['Unit'] = results[['Unit','ParAbb']].apply(lambda x: condunitfix(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results['ResultValue'] = results[['ResultValue','ParAbb']].apply(lambda x: pHfix(x),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize All Fields by date and count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot the data so that parameters are now columns.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datap = results.pivot(index='SampleId', columns='ParAbb', values='ResultValue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns from the pivot table that are pretty much empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datap.dropna(subset=['SO4','Cond','Temp','TDS','pH'],how='all',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table lost the `StationId` field when it was pivoted, so now we need to add the `StationId` field back on to the table by joining it to the previous results table using the `SampleId` field.  First we parse down the results table to only the information we want to retain, then we join the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resdrop = ['AnalysisDate', 'AnalytMeth', 'AnalytMethId',\n",
    "             'DetectCond', 'LabComments', 'LabName', 'LimitType',\n",
    "             'MDL', 'MDLUnit', 'MethodDescript',\n",
    "             'OrgId', 'OrgName', 'Param', 'ProjectId',\n",
    "             'QualCode', 'ResultComment', 'ResultStatus', 'ResultValue',\n",
    "             'SampComment', 'SampDepth',\n",
    "             'SampDepthRef', 'SampDepthU', 'SampEquip', 'SampFrac',\n",
    "             'SampMedia', 'SampMeth', 'SampMethName', 'SampType',\n",
    "             'Unit', 'ParAbb']\n",
    "resPivot = results.drop(resdrop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datapiv = pd.merge(datap, resPivot, left_index=True, right_on='SampleId',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a `StationId` field, we can add our station data, but only the data that will be useful for plotting our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pivStats = station.drop(['Aquifer', 'ConstDate', 'Depth', 'DepthUnit',\n",
    "                         'HoleDUnit', 'HoleDepth', \n",
    "                         'OrgId', 'StationComment', 'StationName', 'matchid'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datapiv = pd.merge(datapiv, pivStats, left_on='StationId', right_index=True,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datapiv.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#datapiv.to_csv(rootname+\"AllResultsPivot.csv\", chunksize=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Create Table For Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "piperdata = datapiv.dropna(subset = ['Ca','Na','Cl','K','Mg','SO4'],how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Relationship between Bicarbonate and Alkalinity.  Fill in missing bicarbonate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0941152486856753, 20.027751188998934, 0.97224865250018067, 0.0, 0.0025819900883626017)\n"
     ]
    }
   ],
   "source": [
    "piv = piperdata.ix[:,['Alk','HCO3']]\n",
    "piv = piv[(piv.Alk < 5000)&(piv.HCO3 < 5000)]\n",
    "piv = piv[(piv.Alk > 0)&(piv.HCO3 > 0)]\n",
    "piv.dropna(inplace=True)\n",
    "lin = linregress(piv.Alk.values,piv.HCO3.values)\n",
    "print lin\n",
    "piperdata.ix[:,\"HCO3\"] = piperdata.apply(lambda x: x['Alk']*lin[0]+lin[1] if np.isnan(x['HCO3']) else x['HCO3'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "piperdata = piperdata.drop(['Alk','As','CO2','Cu','DO','NaK','PO4'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "piperdata.dropna(subset=['Lat_Y','HCO3'], how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "StatFreq = piperdata.groupby('StationId')['StationId'].agg([np.count_nonzero]).reset_index()\n",
    "piperdata = pd.merge(piperdata, StatFreq, on='StationId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "piperdata.to_csv(rootname+\"PiperData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#datapiv.groupby('HU_10_NAME')['Temp'].agg([np.min, np.mean, np.median, np.max, np.std, np.size]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = list(set(list(datapiv.columns)) - set(['SampleDate', 'SampleId', 'StationId', 'FmType', 'Lat_Y', \n",
    "                                          'Lon_X', 'OrgName', 'StationType','DEM','HorCollMet','PLSS','USGSCAD',\n",
    "                                              'UNITNAME', 'Elev', 'MAP_UNIT_SYMBOL', u'HUC_12', u'HUC_10',\n",
    "                                              'Depth', u'OBJECTID', u'ElevUnit',u'HU_12_NAME',u'HU_10_NAME']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\ArcGIS10.3\\lib\\site-packages\\IPython\\kernel\\__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "rc('font', family='Arial')\n",
    "pdf = PdfPages(rootname+'geoboxes.pdf')\n",
    "j = {}\n",
    "for i in range(len(names)):\n",
    "    fms = datapiv[[names[i],'FmType']]\n",
    "    fms.dropna(inplace=True)\n",
    "    fms = fms[~fms['FmType'].isin([' ','', np.nan, 'Green River Formation', 'Rock Springs Formation of Mesaverde Group', \n",
    "                                   'Holocene Alluvium', 'Masuk Member of Mancos Shale', \n",
    "                                   'Tununk Shale Member of Mancos Shale', 'Blue Gate Shale Member of Mancos Shale', \n",
    "                                   'Emery Sandstone Member of Mancos Shale', 'Pleistocene Series', 'Paleozoic Erathem'])]\n",
    "    if len(fms)>30:\n",
    "        j[names[i]] = fms.groupby('FmType')[names[i]].agg([np.min, np.mean, np.median, np.max, np.std, np.size]).reset_index()\n",
    "        labs = [str(j[names[i]]['FmType'][b]) + \" (n=\" + str(int(j[names[i]]['size'][b])) + \")\" for b in range(len(j[names[i]]['FmType']))]\n",
    "        tickloc = [b+1 for b in range(len(j[names[i]]['FmType']))]\n",
    "        ax = fms.boxplot(column=names[i], by='FmType', vert=False)\n",
    "        plt.title(ParAbb.keys()[ParAbb.values().index(names[i])])\n",
    "        plt.suptitle('')\n",
    "        plt.yticks(tickloc, labs)\n",
    "        fig = ax.get_figure()\n",
    "        if ParUnAbb.get(names[i],'') == '':\n",
    "            units = names[i]\n",
    "        else:\n",
    "            units = u'%s (%s)'%(names[i],ParUnAbb.get(names[i]))\n",
    "        plt.xlabel(units)     \n",
    "        if np.max(fms[names[i]].values) > 100:\n",
    "            plt.xscale('log')  \n",
    "        plt.tight_layout()      \n",
    "        pdf.savefig(fig)\n",
    "        plt.close()\n",
    "pdf.close()\n",
    "parsum = pd.concat(j)\n",
    "parsum.to_csv(rootname + \"geology_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\ArcGIS10.3\\lib\\site-packages\\IPython\\kernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "pdf = PdfPages(rootname+'hucboxes.pdf')\n",
    "j = {}\n",
    "for i in range(len(names)):\n",
    "    hucs = datapiv[[names[i],'HU_10_NAME']]\n",
    "    hucs.dropna(inplace=True)\n",
    "    hucs = hucs[~hucs['HU_10_NAME'].isin([' ','', np.nan, 'Spanish Fork Creek',\n",
    "                                          'Twelvemile Creek','Chicken Creek','North Salt Wash', 'West Creek'])]\n",
    "    if len(hucs)>30:\n",
    "        j[names[i]] = hucs.groupby('HU_10_NAME')[names[i]].agg([np.min, np.mean, np.median, np.max, np.std, np.size]).reset_index()\n",
    "        labs = [str(j[names[i]]['HU_10_NAME'][b]) + \" (n=\" + str(int(j[names[i]]['size'][b])) + \")\" for b in range(len(j[names[i]]['HU_10_NAME']))]\n",
    "        tickloc = [b+1 for b in range(len(j[names[i]]['HU_10_NAME']))]              \n",
    "        ax = hucs.boxplot(column=names[i],by='HU_10_NAME',vert=False)\n",
    "        plt.suptitle('')\n",
    "        plt.title(ParAbb.keys()[ParAbb.values().index(names[i])])\n",
    "        plt.yticks(tickloc, labs)\n",
    "        fig = ax.get_figure() \n",
    "        if ParUnAbb.get(names[i],'') == '':\n",
    "            units = names[i]\n",
    "        else:\n",
    "            units = names[i] +' (' + u'%s'% (ParUnAbb.get(names[i])) +')'\n",
    "        plt.xlabel(units) \n",
    "        if np.max(hucs[names[i]].values) > 100:\n",
    "            plt.xscale('log')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        pdf.savefig(fig)\n",
    "        plt.close()\n",
    "pdf.close()\n",
    "parsum = pd.concat(j)\n",
    "parsum.to_csv(rootname + \"stream_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datapivcor = datapiv.dropna(subset=['TDS','Q'],how='any')\n",
    "datapivcor = datapivcor[datapivcor['Q']>1]\n",
    "datapivcor = datapivcor[datapivcor['TDS']<10000]\n",
    "datapivcor = datapivcor[datapivcor['StationType'].isin(['Stream','Spring'])]\n",
    "pdf = PdfPages(rootname+'Q_TDS.pdf')\n",
    "\n",
    "for key, grp in datapivcor.groupby(['StationId']):\n",
    "    lin = linregress(grp['Q'],grp['TDS'])\n",
    "    if len(grp) > 3:\n",
    "        if lin[2]>0.5:\n",
    "            fig = plt.figure()\n",
    "            plt.scatter(x=grp['Q'],y= grp['TDS'], label=key)\n",
    "            plt.title(str(key) + ' ' +str(grp['StationType'].values[0]))\n",
    "            plt.xlabel('Discharge (gpm)')\n",
    "            plt.ylabel('TDS (mg/L)')\n",
    "            plt.legend(loc='best')    \n",
    "            pdf.savefig(fig)\n",
    "            plt.close()\n",
    "pdf.close()\n",
    "    \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
