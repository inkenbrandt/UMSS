{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from numpy import dtype\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams, rc\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "#from __future__ import unicode_literals\n",
    "\n",
    "#%matplotlib inline\n",
    "#rcParams['figure.figsize'] = 15, 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOGM Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utah Division of Oil Gas and Mining (DOGM) data derived from the <a href=http://linux1.ogm.utah.gov/WebStuff/wwwroot/wqdb.html>DOGM website</a>. Station information obtained from digitization of PDF maps provided by mining companies to DOGM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ubuntu rootname = \"/media/p/5F5B-8FCB/PROJECTS/MLSNF/Data/CHEM/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rootname = \"E:/PROJECTS/MLSNF/Data/CHEM/\"\n",
    "rootname = \"U:/GWP/Groundwater/UMSS_Manti/Data/\"\n",
    "#rootname = \"/media/p/5F5B-8FCB/PROJECTS/MLSNF/Data/CHEM/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOGM = rootname + \"DOGM/UDOGM_allResults.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOGM_ST = rootname + \"DOGM/dogm_stations.xls\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and Prepare DOGM Results Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parmatch = {\"ACIDITY AS CACO3\":\"Acidity\", \"TOTAL ALKALINITY AS CACO3\":\"Alkalinity, total\", \n",
    "            \"DISSOLVED ALUMINUM\":\"Aluminum\", \"TOTAL ALUMINUM\":\"Aluminum\", \"AMMONIA AS N\":\"Ammonia-nitrogen as N\", \n",
    "            \"DISSOLVED ARSENIC\":\"Arsenic\", \"TOTAL ARSENIC\":\"Arsenic\", \"DISSOLVED BARIUM\":\"Barium\", \n",
    "            \"TOTAL BARIUM\":\"Barium\", \"TOTAL BERYLLIUM\":\"Beryllium\", \"BICARBONATE AS HCO3\":\"Bicarbonate\", \n",
    "            \"B.O.D. 5, MG/L\":\"Biochemical oxygen demand, standard conditions\", \"DISSOLVED BORON\":\"Boron\", \n",
    "            \"TOTAL BORON\":\"Boron\", \"BROMIDE\":\"Bromide\", \"DISSOLVED CADMIUM\":\"Cadmium\", \"TOTAL CADMIUM\":\"Cadmium\", \n",
    "            \"DISSOLVED CALCIUM\":\"Calcium\", \"TOTAL CALCIUM\":\"Calcium\", \"CARBONATE AS CO3\":\"Carbonate\", \n",
    "            \"C.O.D., MG/L\":\"Chemical oxygen demand\", \"CHLORIDE\":\"Chloride\", \"DISSOLVED CHROMIUM\":\"Chromium\", \n",
    "            \"TOTAL CHROMIUM\":\"Chromium\", \"CHROMIUM HEX, CR\":\"Chromium(VI)\", \"TOTAL COBALT\":\"Cobalt\", \n",
    "            \"SP. CONDUCTIVITY (FIELD)\":\"Conductivity\", \"SPECIFIC CONDUCTIVITY (LAB)\":\"Conductivity\", \n",
    "            \"DISSOLVED COPPER\":\"Copper\", \"TOTAL COPPER\":\"Copper\", \"CYANIDE\":\"Cyanide\", \"DEPTH\":\"Depth\", \n",
    "            \"DISSOLVED OXYGEN (FIELD)\":\"Dissolved oxygen (DO)\", \"FLOW\":\"Flow\", \"FLUORIDE\":\"Fluoride\", \n",
    "            \"TOTAL HARDNESS AS CACO3\":\"Hardness, Ca, Mg\", \"HYDROXIDE\":\"Hydroxide\", \"DISSOLVED IRON\":\"Iron\", \n",
    "            \"TOTAL IRON\":\"Iron\", \"TOTAL KIELDAHL NITROGEN, T.K.N.\":\"Kjeldahl nitrogen\", \"DISSOLVED LEAD\":\"Lead\", \n",
    "            \"TOTAL LEAD\":\"Lead\", \"DISSOLVED MAGNESIUM\":\"Magnesium\", \"TOTAL MAGNESIUM\":\"Magnesium\", \n",
    "            \"DISSOLVED MANGANESE\":\"Manganese\", \"TOTAL MANGANESE\":\"Manganese\", \"DISSOLVED MERCURY\":\"Mercury\", \n",
    "            \"TOTAL MERCURY\":\"Mercury\", \"DISSOLVED MOLYBDENUM\":\"Molybdenum\", \"TOTAL MOLYBDENUM\":\"Molybdenum\", \n",
    "            \"DISSOLVED NICKEL\":\"Nickel\", \"TOTAL NICKEL\":\"Nickel\", \"DISSOLVED NITRATE, NO3\":\"Nitrate\", \n",
    "            \"NITRATE AS N\":\"Nitrate as N\", \"DISSOLVED NITRITE, NO2\":\"Nitrite\", \"NITRITE AS N\":\"Nitrogen\", \n",
    "            \"NO2+NO3 AS N\":\"Nitrogen\", \"DISSOLVED ORTHO PHOSPH, OPO4\":\"Orthophosphate\", \n",
    "            \"ORTHO. PHOSPHATE\":\"Orthophosphate\", \"PH (FIELD)\":\"pH\", \"PH (LAB)\":\"pH, lab\", \n",
    "            \"TOTAL PHOSPHORUS\":\"Phosphorus\", \"DISSOLVED POTASSIUM\":\"Potassium\", \"DISSOLVED SELENIUM\":\"Selenium\", \n",
    "            \"TOTAL SELENIUM\":\"Selenium\", \"DISSOLVED SILICA, SIO2\":\"Silica\", \"DISSOLVED SILVER\":\"Silver\", \n",
    "            \"TOTAL SILVER\":\"Silver\", \"DISSOLVED SODIUM\":\"Sodium\", \"TOTAL SODIUM\":\"Sodium\", \n",
    "            \"SODIUM ADSORPTION RATIO\":\"Sodium adsorption ratio\", \"SULFATE\":\"Sulfate\", \"SULFIDE\":\"Sulfide\", \n",
    "            \"TOTAL ANIONS\":\"Sum of anions\", \"TOTAL CATIONS\":\"Sum of cations\", \n",
    "            \"AIR TEMPERATURE (FIELD)\":\"Temperature, air\", \"FIELD WATER TEMPERATURE\":\"Temperature, water\", \n",
    "            \"TOTAL DISSOLVED SOLIDS, @ 180 C\":\"Total dissolved solids\", \n",
    "            \"TOTAL SUSPENDED SOLIDS\":\"Total suspended solids\", \"TURBIDITY (FIELD)\":\"Turbidity\", \n",
    "            \"TURBIDITY (LAB)\":\"Turbidity\", \"TOTAL VANADIUM\":\"Vanadium\", \"DISSOLVED ZINC\":\"Zinc\", \"TOTAL ZINC\":\"Zinc\"} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dogtypes = {'Unnamed: 0':dtype('int8'),'MIN_DET': dtype('float32'), 'MINE_ID': dtype('int8'), \n",
    "            'ANAL_NAME': dtype('str_'), 'PARAM_ID': dtype('int8'), 'SAMPLE_ID': dtype('str_'), 'SITE_NAME': dtype('str_'), \n",
    "            'METHD': dtype('str_'), 'DATE_REC': dtype('str_'),'EQUALITY': dtype('str_'), 'TIME_ANAL': dtype('str_'), \n",
    "            'STATION_ID': dtype('str_'), 'PAR_DESC': dtype('str_'), 'PAR_ABB': dtype('str_'), 'ANAL_METHD': dtype('str_'), \n",
    "            'METH_DESC': dtype('str_'), 'SAMP_TYPE': dtype('str_'), 'LAB_ID': dtype('str_'), 'MINE_NAME': dtype('str_'), \n",
    "            'SITE_DESC': dtype('str_'), 'SITE_ID': dtype('int8'), 'VALUE': dtype('float32'), 'PERM_NO': dtype('str_'), \n",
    "            'LAB_NAME': dtype('str_'), 'UNITS': dtype('str_'), 'SAMP_DESC': dtype('str_'), 'DATE_ANAL': dtype('str_'), \n",
    "            'SITE_TYPE': dtype('str_'), 'LAB_CODE': dtype('str_'), 'SAMPLR_NAM': dtype('str_'), 'COMMENTS': dtype('str_')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dogmr = pd.read_csv(DOGM, dtype=dogtypes, parse_dates=[11,14,15,19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DResCols = {\"ANAL_METHD\":\"AnalytMeth\", \"ANAL_NAME\":\"Param\", \"COMMENTS\":\"ResultComment\", \"DATE_ANAL\":\"AnalysisDate\", \n",
    "            \"DATETIME_SAMP\":\"SampleDate\", \"EQUALITY\":\"DetectCond\", \"LAB_CODE\":\"LabComments\", \"LAB_NAME\":\"LabName\", \n",
    "            \"METH_DESC\":\"MethodDescript\", \"METHD\":\"SampMeth\", \"MIN_DET\":\"MDL\", \"SAMP_TYPE\":\"SampMethName\", \n",
    "            \"SAMPLE_ID\":\"SampleId\", \"STATION_ID\":\"StationId\", \"UNITS\":\"Unit\", \"VALUE\":\"ResultValue\"} \n",
    "dogmr.rename(columns=DResCols,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dogmr['Param'] = dogmr['PAR_DESC'].apply(lambda x: parmatch.get(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dogmr.dropna(how='any',subset=['StationId'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dogmr.drop(['PARAM_ID','SAMPLR_NAM','SITE_ID','SITE_DESC','PAR_DESC','TIME_ANAL','DATE_RPT',\n",
    "            'DATE_REC','Unnamed: 0', 'LAB_ID','MINE_ID','PAR_ABB','MINE_NAME', 'SITE_NAME', 'SAMP_DESC',\n",
    "            'PERM_NO','SITE_TYPE'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'LabComments', u'DetectCond', u'ResultValue', u'Unit', u'MDL',\n",
       "       u'AnalytMeth', u'AnalysisDate', u'Param', u'SampMethName',\n",
       "       u'ResultComment', u'SampleDate', u'SampMeth', u'MethodDescript',\n",
       "       u'LabName', u'SampleId', u'StationId'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogmr.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Import and Prepare DOGM Station Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dogms = pd.read_excel(DOGM_ST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consolidate descriptor columns into `StationComment` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##WQP Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data downloaded from the <a href=http://waterqualitydata.us/portal/>Water Quality Portal (WQP)</a> on 7/22/2015. <br>\n",
    "<b>Stations:</b><br>\n",
    "http://waterqualitydata.us/Station/search?sampleMedia=Water&characteristicType=Information%3BInorganics%2C+Major%2C+Metals%3BInorganics%2C+Major%2C+Non-metals%3BInorganics%2C+Minor%2C+Metals%3BInorganics%2C+Minor%2C+Non-metals%3BNot+Assigned%3BNutrient%3BPhysical%3BStable+Isotopes&bBox=-111.68%2C38.8%2C-111%2C40&mimeType=csv&zip=yes&sorted=no <br>\n",
    "<b>Results:</b><br>\n",
    "http://waterqualitydata.us/Result/search?sampleMedia=Water&characteristicType=Information%3BInorganics%2C+Major%2C+Metals%3BInorganics%2C+Major%2C+Non-metals%3BInorganics%2C+Minor%2C+Metals%3BInorganics%2C+Minor%2C+Non-metals%3BNot+Assigned%3BNutrient%3BPhysical%3BStable+Isotopes&bBox=-111.68%2C38.8%2C-111%2C40&mimeType=csv&zip=yes&sorted=no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define location of data downloaded from the Water Quality Portal site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = rootname +\"WQP/Result.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Results Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map data types for data to be imported and designate columns to convert to datetimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rdtypes = {\"OrganizationIdentifier\":np.str_, \"OrganizationFormalName\":np.str_, \"ActivityIdentifier\":np.str_, \n",
    "           \"ActivityTypeCode\":np.str_, \"ActivityMediaName\":np.str_, \"ActivityMediaSubdivisionName\":np.str_, \n",
    "           \"ActivityStartDate\":np.str_, \"ActivityStartTime/Time\":np.str_, \"ActivityStartTime/TimeZoneCode\":np.str_, \n",
    "           \"ActivityEndDate\":np.str_, \"ActivityEndTime/Time\":np.str_, \"ActivityEndTime/TimeZoneCode\":np.str_, \n",
    "           \"ActivityDepthHeightMeasure/MeasureValue\":np.float16, \"ActivityDepthHeightMeasure/MeasureUnitCode\":np.str_, \n",
    "           \"ActivityDepthAltitudeReferencePointText\":np.str_, \"ActivityTopDepthHeightMeasure/MeasureValue\":np.float16, \n",
    "           \"ActivityTopDepthHeightMeasure/MeasureUnitCode\":np.str_, \n",
    "           \"ActivityBottomDepthHeightMeasure/MeasureValue\":np.float16, \n",
    "           \"ActivityBottomDepthHeightMeasure/MeasureUnitCode\":np.str_, \n",
    "           \"ProjectIdentifier\":np.str_, \"ActivityConductingOrganizationText\":np.str_, \n",
    "           \"MonitoringLocationIdentifier\":np.str_, \"ActivityCommentText\":np.str_, \n",
    "           \"SampleAquifer\":np.str_, \"HydrologicCondition\":np.str_, \"HydrologicEvent\":np.str_, \n",
    "           \"SampleCollectionMethod/MethodIdentifier\":np.str_, \"SampleCollectionMethod/MethodIdentifierContext\":np.str_, \n",
    "           \"SampleCollectionMethod/MethodName\":np.str_, \"SampleCollectionEquipmentName\":np.str_, \n",
    "           \"ResultDetectionConditionText\":np.str_, \"CharacteristicName\":np.str_, \"ResultSampleFractionText\":np.str_, \n",
    "           \"ResultMeasureValue\":np.str_, \"ResultMeasure/MeasureUnitCode\":np.str_, \"MeasureQualifierCode\":np.str_, \n",
    "           \"ResultStatusIdentifier\":np.str_, \"StatisticalBaseCode\":np.str_, \"ResultValueTypeName\":np.str_, \n",
    "           \"ResultWeightBasisText\":np.str_, \"ResultTimeBasisText\":np.str_, \"ResultTemperatureBasisText\":np.str_, \n",
    "           \"ResultParticleSizeBasisText\":np.str_, \"PrecisionValue\":np.str_, \"ResultCommentText\":np.str_, \n",
    "           \"USGSPCode\":np.str_, \"ResultDepthHeightMeasure/MeasureValue\":np.float16, \n",
    "           \"ResultDepthHeightMeasure/MeasureUnitCode\":np.str_, \"ResultDepthAltitudeReferencePointText\":np.str_, \n",
    "           \"SubjectTaxonomicName\":np.str_, \"SampleTissueAnatomyName\":np.str_, \n",
    "           \"ResultAnalyticalMethod/MethodIdentifier\":np.str_, \"ResultAnalyticalMethod/MethodIdentifierContext\":np.str_, \n",
    "           \"ResultAnalyticalMethod/MethodName\":np.str_, \"MethodDescriptionText\":np.str_, \"LaboratoryName\":np.str_, \n",
    "           \"AnalysisStartDate\":np.str_, \"ResultLaboratoryCommentText\":np.str_, \n",
    "           \"DetectionQuantitationLimitTypeName\":np.str_, \"DetectionQuantitationLimitMeasure/MeasureValue\":np.str_, \n",
    "           \"DetectionQuantitationLimitMeasure/MeasureUnitCode\":np.str_, \"PreparationStartDate\":np.str_, \n",
    "           \"ProviderName\":np.str_} \n",
    "\n",
    "dt = [[6,7],56,61]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import result data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = pd.read_csv(result, dtype=Rdtypes, parse_dates=dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(list(res['CharacteristicName'].unique())).to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remap column names to standards and drop unneeded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ResFieldDict = {\"AnalysisStartDate\":\"AnalysisDate\", \"ResultAnalyticalMethod/MethodIdentifier\":\"AnalytMeth\", \n",
    "                \"ResultAnalyticalMethod/MethodName\":\"AnalytMethId\", \"ResultDetectionConditionText\":\"DetectCond\", \n",
    "                \"ResultLaboratoryCommentText\":\"LabComments\", \"LaboratoryName\":\"LabName\", \n",
    "                \"DetectionQuantitationLimitTypeName\":\"LimitType\", \"DetectionQuantitationLimitMeasure/MeasureValue\":\"MDL\", \n",
    "                \"DetectionQuantitationLimitMeasure/MeasureUnitCode\":\"MDLUnit\", \"MethodDescriptionText\":\"MethodDescript\", \n",
    "                \"OrganizationIdentifier\":\"OrgId\", \"OrganizationFormalName\":\"OrgName\", \"CharacteristicName\":\"Param\", \n",
    "                \"ProjectIdentifier\":\"ProjectId\", \"MeasureQualifierCode\":\"QualCode\", \"ResultCommentText\":\"ResultComment\", \n",
    "                \"ResultStatusIdentifier\":\"ResultStatus\", \"ResultMeasureValue\":\"ResultValue\", \n",
    "                \"ActivityCommentText\":\"SampComment\", \"ActivityDepthHeightMeasure/MeasureValue\":\"SampDepth\", \n",
    "                \"ActivityDepthAltitudeReferencePointText\":\"SampDepthRef\", \n",
    "                \"ActivityDepthHeightMeasure/MeasureUnitCode\":\"SampDepthU\", \"SampleCollectionEquipmentName\":\"SampEquip\", \n",
    "                \"ResultSampleFractionText\":\"SampFrac\", \"ActivityStartDate\":\"SampleDate\", \"ActivityIdentifier\":\"SampleId\", \n",
    "                \"ActivityStartTime/Time\":\"SampleTime\", \"ActivityMediaSubdivisionName\":\"SampMedia\", \n",
    "                \"SampleCollectionMethod/MethodIdentifier\":\"SampMeth\", \"SampleCollectionMethod/MethodName\":\"SampMethName\", \n",
    "                \"ActivityTypeCode\":\"SampType\", \"MonitoringLocationIdentifier\":\"StationId\", \n",
    "                \"ResultMeasure/MeasureUnitCode\":\"Unit\", \"USGSPCode\":\"USGSPCode\",\n",
    "                \"ActivityStartDate_ActivityStartTime/Time\":\"SampleDate\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res.rename(columns=ResFieldDict,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resdroplist = [\"ActivityBottomDepthHeightMeasure/MeasureUnitCode\", \"ActivityBottomDepthHeightMeasure/MeasureValue\", \n",
    "               \"ActivityConductingOrganizationText\", \"ActivityEndDate\", \"ActivityEndTime/Time\", \n",
    "               \"ActivityEndTime/TimeZoneCode\", \"ActivityMediaName\", \"ActivityStartTime/TimeZoneCode\", \n",
    "               \"ActivityTopDepthHeightMeasure/MeasureUnitCode\", \"ActivityTopDepthHeightMeasure/MeasureValue\", \n",
    "               \"HydrologicCondition\", \"HydrologicEvent\", \"PrecisionValue\", \"PreparationStartDate\", \"ProviderName\", \n",
    "               \"ResultAnalyticalMethod/MethodIdentifierContext\", \"ResultDepthAltitudeReferencePointText\", \n",
    "               \"ResultDepthHeightMeasure/MeasureUnitCode\", \"ResultDepthHeightMeasure/MeasureValue\", \n",
    "               \"ResultParticleSizeBasisText\", \"ResultTemperatureBasisText\", \n",
    "               \"ResultTimeBasisText\", \"ResultValueTypeName\", \"ResultWeightBasisText\", \"SampleAquifer\", \n",
    "               \"SampleCollectionMethod/MethodIdentifierContext\", \"SampleTissueAnatomyName\", \"StatisticalBaseCode\", \n",
    "               \"SubjectTaxonomicName\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res.drop(resdroplist,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert string fields to values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res['ResultValue'] = res['ResultValue'].convert_objects(convert_numeric=True)\n",
    "res['MDL'] = res['MDL'].convert_objects(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `_WQX` suffix from `StationID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res['StationId'] = res['StationId'].str.replace('_WQX-','-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Station Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'station' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-820deb77439c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'station' is not defined"
     ]
    }
   ],
   "source": [
    "stat = pd.read_csv(station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map Fields to Standard UGS database format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "StatFieldDict = {\"MonitoringLocationIdentifier\":\"StationId\", \"AquiferName\":\"Aquifer\", \"AquiferTypeName\":\"AquiferType\", \n",
    "             \"ConstructionDateText\":\"ConstDate\", \"CountyCode\":\"CountyCode\", \"WellDepthMeasure/MeasureValue\":\"Depth\", \n",
    "             \"WellDepthMeasure/MeasureUnitCode\":\"DepthUnit\", \"VerticalMeasure/MeasureValue\":\"Elev\", \n",
    "             \"VerticalAccuracyMeasure/MeasureValue\":\"ElevAcc\", \"VerticalAccuracyMeasure/MeasureUnitCode\":\"ElevAccUnit\", \n",
    "             \"VerticalCollectionMethodName\":\"ElevMeth\", \"VerticalCoordinateReferenceSystemDatumName\":\"ElevRef\", \n",
    "             \"VerticalMeasure/MeasureUnitCode\":\"ElevUnit\", \"FormationTypeText\":\"FmType\", \n",
    "             \"WellHoleDepthMeasure/MeasureValue\":\"HoleDepth\", \"WellHoleDepthMeasure/MeasureUnitCode\":\"HoleDUnit\", \n",
    "             \"HorizontalAccuracyMeasure/MeasureValue\":\"HorAcc\", \"HorizontalAccuracyMeasure/MeasureUnitCode\":\"HorAccUnit\", \n",
    "             \"HorizontalCollectionMethodName\":\"HorCollMeth\", \"HorizontalCoordinateReferenceSystemDatumName\":\"HorRef\", \n",
    "             \"HUCEightDigitCode\":\"HUC8\", \"LatitudeMeasure\":\"Lat_Y\", \"LongitudeMeasure\":\"Lon_X\", \n",
    "             \"OrganizationIdentifier\":\"OrgId\", \"OrganizationFormalName\":\"OrgName\", \"StateCode\":\"StateCode\", \n",
    "             \"MonitoringLocationDescriptionText\":\"StationComment\", \"MonitoringLocationName\":\"StationName\", \n",
    "             \"MonitoringLocationTypeName\":\"StationType\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stat.rename(columns=StatFieldDict,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop leftover fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statdroplist = [\"ContributingDrainageAreaMeasure/MeasureUnitCode\", \"ContributingDrainageAreaMeasure/MeasureValue\", \n",
    "                \"DrainageAreaMeasure/MeasureUnitCode\", \"DrainageAreaMeasure/MeasureValue\", \"CountryCode\", \"ProviderName\", \n",
    "                \"SourceMapScaleNumeric\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stat.drop(statdroplist,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `_WQX` suffix from `StationID` and take out duplicate stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stat['StationId'] = stat['StationId'].str.replace('_WQX-','-')\n",
    "stat.drop_duplicates(subset=['StationId'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Combine Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append Results Data Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.concat([res,dogmr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del(res,dogmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ParAbb = {\"Alkalinity\":\"Alk\", \"Alkalinity, Carbonate as CaCO3\":\"Alk\", \"Alkalinity, total\":\"Alk\", \n",
    "          \"Arsenic\":\"As\", \"Calcium\":\"Ca\", \"Chloride\":\"Cl\", \"Carbon dioxide\":\"CO2\", \"Carbonate\":\"CO3\", \n",
    "          \"Carbonate (CO3)\":\"CO3\", \"Specific conductance\":\"Cond\", \"Conductivity\":\"Cond\", \"Copper\":\"Cu\", \n",
    "          \"Depth\":\"Depth\", \"Dissolved oxygen (DO)\":\"DO\", \"Iron\":\"Fe\", \n",
    "          \"Hardness, Ca, Mg\":\"Hard\", \"Total hardness -- SDWA NPDWR\":\"Hard\", \n",
    "          \"Bicarbonate\":\"HCO3\", \"Potassium\":\"K\", \"Magnesium\":\"Mg\", \"Kjeldahl nitrogen\":\"N\", \n",
    "          \"Nitrogen, mixed forms (NH3), (NH4), organic, (NO2) and (NO3)\":\"N\", \"Nitrogen\":\"N\", \"Sodium\":\"Na\", \n",
    "          \"Sodium plus potassium\":\"NaK\", \"Ammonia-nitrogen\":\"NH3_N\", \"Ammonia-nitrogen as N\":\"N\", \"Nitrite\":\"NO2\", \n",
    "          \"Nitrate\":\"NO3\", \"Nitrate as N\":\"N\", \"pH, lab\":\"pH\", \"pH\":\"pH\",  \"Phosphate-phosphorus\":\"PO4\", \n",
    "          \"Orthophosphate\":\"PO4\", \"Phosphate\":\"PO4\", \"Stream flow, instantaneous\":\"Q\", \"Flow\":\"Q\", \n",
    "          \"Flow rate, instantaneous\":\"Q\", \"Silica\":\"Si\", \"Sulfate\":\"SO4\", \"Sulfate as SO4\":\"SO4\", \n",
    "          \"Total dissolved solids\":\"TDS\", \"Temperature, water\":\"Temp\", \n",
    "          \"Total suspended solids\":\"TSS\", \"Turbidity\":\"Turb\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ParUnAbb = {'Alk':u'mg/L', 'As':u'\\u03BCg/L', 'Ca':u'mg/L', 'Cl':u'mg/L', 'CO2':u'mg/L', 'CO3':u'mg/L', 'Cond':u'\\u03BChoms/cm',\n",
    "           'Cu':u'\\u03BCg/L', 'DO':u'mg/L', 'Hard':u'mg/L', 'HCO3':u'mg/L', 'K':u'mg/L', 'Mg':u'mg/L', 'N':u'mg/L', 'pH':u'', \n",
    "            'Q':u'gpm', 'Fe':u'\\u03BCg/L', 'TDS':u'mg/L', 'Si':u'mg/L', 'SO4':u'mg/L', 'Temp':u'\\N{DEGREE SIGN}C', 'PO4':u'mg/L', 'TSS':u'mg/L',\n",
    "           'Turb':u'Turb. Units', 'Na':u'mg/L', 'NaK':u'mg/L', 'NO3':u'mg/L', 'NH3':u'mg/L', 'NO2':u'mg/L', 'NH3_N':u'mg/L'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results['ParAbb'] = results['Param'].apply(lambda x: ParAbb.get(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del results['USGSPCode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#results.to_csv(rootname+\"AllResults.csv\", chunksize=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dogms.set_index(['StationId'],inplace=True)\n",
    "station = dogms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station[\"index\"] = station.index\n",
    "station.drop_duplicates(subset='index', take_last=True, inplace=True)\n",
    "del station[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stattype = {\"Stream: Ditch\":\"Stream\", \"Stream\":\"Stream\", \"Well\":\"Well\", \"Spring\":\"Spring\", \n",
    "            \"Stream: Canal\":\"Stream\", \"Subsurface: Tunnel, shaft, or mine\":\"Mine Drain\", \n",
    "            \"Well: Test hole not completed as a well\":\"Well\", \"Subsurface: Groundwater drain\":\"Mine Drain\", \n",
    "            \"Lake, Reservoir, Impoundment\":\"Lake\", \"River/Stream\":\"Stream\", \"Lake\":\"Lake\", \"Facility Other\":\"Other\", \n",
    "            \"Canal Drainage\":\"Stream\", \"Canal Irrigation\":\"Stream\", \"MD\":\"Mine Drain\", \"SW\":\"Stream\", \"GW\":\"Well\", \n",
    "            \"SP\":\"Spring\", \"UPDES Permit discharge point\":\"Mine Drain\", \"Lake; Sediment Pond; Stagnant water\":\"Lake\", \n",
    "            \"Other\":\"Other\", \"CG-2\":\"Other\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "station['StationType'] = station['StationType'].apply(lambda x: stattype.get(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fmdict = {\"Blackhawk Formation of Mesaverde Group\":4, \"Castlegate Sandstone of Mesaverde Group\":5, \n",
    "          \"Ferron Sandstone Member of Mancos Shale\":2, \"Flagstaff Limestone (Eocene-Paleocene)\":8, \n",
    "          \"Green River Formation\":10, \"Mancos Shale\":1, \"North Horn Formation (Paleocene-Upper Cretaceous)\":7,\n",
    "          \"Paleozoic Erathem\":0, \"Price River Formation of Mesaverde Group\":6,\n",
    "          \"Star Point Sandstone of Mesaverde Group\":3, \"Valley Fill\":9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([       u'OBJECTID',         u'Aquifer',       u'ConstDate',\n",
       "                 u'Depth',       u'DepthUnit',          u'FmType',\n",
       "             u'HoleDUnit',       u'HoleDepth',      u'HorCollMet',\n",
       "                 u'Lat_Y',           u'Lon_X',           u'OrgId',\n",
       "               u'OrgName',  u'StationComment',     u'StationName',\n",
       "           u'StationType',         u'matchid',            u'PLSS',\n",
       "               u'USGSCAD', u'MAP_UNIT_SYMBOL',            u'Elev',\n",
       "              u'ElevUnit',          u'HUC_10',          u'HUC_12',\n",
       "            u'HU_10_NAME',      u'HU_12_NAME'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station['FmNum'] = station['FmType'].apply(lambda x: fmdict.get(x),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Summarize and Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['StationId', 'Param', 'amin', 'amax', 'size']\n"
     ]
    }
   ],
   "source": [
    "durationsummary = results.groupby(['StationId','Param'])['SampleDate'].agg([np.min,np.max,np.size]).reset_index()\n",
    "durationsummary.convert_objects(convert_numeric=True)\n",
    "print list(durationsummary.columns)\n",
    "durationsummary['amax'] =  durationsummary['amax'].apply(lambda x: str(x).replace('nan','00:00:00'),1)\n",
    "durationsummary['amin'] =  durationsummary['amin'].apply(lambda x: str(x).replace('nan','00:00:00'),1)\n",
    "durationsummary['duration'] = durationsummary['amax'].astype(np.datetime64) - durationsummary['amin'].astype(np.datetime64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'durationsummary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f4d9ac1ee9b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdurationsummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'StationId'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m LongFlow = durationsummary[(durationsummary['Param']=='Flow') & (durationsummary['size']>100) & \n\u001b[0;32m      3\u001b[0m                            (durationsummary['duration']>365*5)]\n\u001b[0;32m      4\u001b[0m \u001b[0mLongFlow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLongFlow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mLongFlow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLongFlow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'durationsummary' is not defined"
     ]
    }
   ],
   "source": [
    "durationsummary.drop_duplicates(subset=['StationId'],inplace=True)\n",
    "LongFlow = durationsummary[(durationsummary['Param']=='Flow') & (durationsummary['size']>100) & \n",
    "                           (durationsummary['duration']>365*5)]\n",
    "LongFlow.amax = LongFlow.amax.astype(np.datetime64)\n",
    "LongFlow.amin = LongFlow.amin.astype(np.datetime64)\n",
    "\n",
    "#durationsummary.reset_index(inplace=True)\n",
    "\n",
    "#durationsummary.set_index(['amax'], inplace=True)\n",
    "#durationsummary['maxtime'] = durationsummary.index.to_julian_date()\n",
    "#durationsummary.reset_index(inplace=True)\n",
    "#durationsummary.set_index(['amin'], inplace=True)\n",
    "#durationsummary['mintime']= durationsummary.index.to_julian_date()\n",
    "#durationsummary.reset_index(inplace=True)\n",
    "#durationsummary.set_index('index', inplace=True)\n",
    "\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 15, 10\n",
    "\n",
    "y = LongFlow.index.values\n",
    "x2 = LongFlow.amax.values\n",
    "x1 = LongFlow.amin.values\n",
    "\n",
    "plt.figure()\n",
    "# Plot a line for every line of data in your file\n",
    "plt.hlines(y, x1, x2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "durationsummary.to_csv(rootname + \"fieldsummaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LongFlow = durationsummary[(durationsummary['Param']=='Flow') & (durationsummary['size']>50) & \n",
    "                           (durationsummary['duration']>365*10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LongFlowList = list(LongFlow['StationId'].values)\n",
    "FlowResGPM = results[(results['StationId'].isin(LongFlowList)) & (results['ResultValue'] != np.nan) & \n",
    "                     (results['Unit']=='GPM')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LongFlowList = list(LongFlow['StationId'].values)\n",
    "FlowResGPM = results[(results['StationId'].isin(LongFlowList)) & (results['ResultValue'] != np.nan) & \n",
    "                     (results['Unit']=='GPM')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\ArcGIS10.3\\lib\\site-packages\\IPython\\kernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Python27\\ArcGIS10.3\\lib\\site-packages\\IPython\\kernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Python27\\ArcGIS10.3\\lib\\site-packages\\IPython\\kernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "FlowResGPM.reset_index(inplace=True)\n",
    "FlowResGPM.set_index('SampleDate',inplace=True)\n",
    "FlowResGPM.sort_index(inplace=True)\n",
    "FlowResGPM['pyDate'] = FlowResGPM.index.to_pydatetime()\n",
    "FlowResGPM['JulDate'] = FlowResGPM.index.to_julian_date()\n",
    "\n",
    "FlowResGPM = pd.merge(FlowResGPM, station, left_on='StationId', right_index=True, how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\ArcGIS10.3\\lib\\site-packages\\IPython\\kernel\\__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "pdf = PdfPages(rootname+'flowres.pdf')\n",
    "\n",
    "xmax = np.max(FlowResGPM['pyDate'].values)\n",
    "xmin = np.min(FlowResGPM['pyDate'].values)\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams.update({'font.size': 10})\n",
    "\n",
    "for key, grp in FlowResGPM.groupby(['StationId']):\n",
    "    if np.max(grp['ResultValue'])>0:\n",
    "        # determine gallons flowing for each time period\n",
    "        grp['Gallons'] = grp['ResultValue'] * grp['JulDate'].diff()*60*24*3.06888328E-6 \n",
    "        y2 = grp['Gallons'].cumsum().values\n",
    "        # filter out graphs smaller than 30 non-zero points\n",
    "        if np.count_nonzero(grp['ResultValue']) > 30:\n",
    "            fig = plt.figure(figsize=(10,8))\n",
    "            title = str(str(grp['StationName'].values[0]) + ' ' + str(grp['StationType'].values[0]))\n",
    "            if title == \"nan nan\":\n",
    "                plt.title(key)\n",
    "            else:\n",
    "                plt.title(title)\n",
    "\n",
    "            ax = fig.add_subplot(111)\n",
    "            ax.plot(grp['pyDate'].values,grp['ResultValue'].values, label='Discharge', linestyle='-', marker='.', color='b')\n",
    "            ax.set_ylabel('Discharge (gpm)')\n",
    "            ax.set_xlabel('Date')\n",
    "            ax.set_xlim([xmin,xmax])\n",
    "\n",
    "            ax2 = ax.twinx()\n",
    "            ax2.plot(grp['pyDate'].values, y2, label='Cumulative Discharge', linestyle='--', color='g')\n",
    "            ax2.set_ylabel('Cumulative Discharge (ac-ft)')\n",
    "\n",
    "\n",
    "            # ask matplotlib for the plotted objects and their labels\n",
    "            lines, labels = ax.get_legend_handles_labels()\n",
    "            lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "            ax2.legend(lines + lines2, labels + labels2, loc='upper left', bbox_to_anchor=(-0.10, 1.15))\n",
    "            ax2.set_xlim([xmin,xmax])\n",
    "            #plt.tight_layout()\n",
    "            pdf.savefig(fig)\n",
    "            plt.close()\n",
    "    \n",
    "\n",
    "\n",
    "d = pdf.infodict()\n",
    "d['Title'] = 'Discharge Data'\n",
    "d['Author'] = u'Paul Inkenbrandt'\n",
    "d['Subject'] = 'Discharge Data from Manti LaSal'\n",
    "d['Keywords'] = 'PdfPages multipage keywords author title subject'\n",
    "d['CreationDate'] = datetime.datetime.today()\n",
    "d['ModDate'] = datetime.datetime.today()\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Pivot Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows from the `results` table that have null `SampleId` values or parameter abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.dropna(subset=['SampleId','ParAbb'],how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows from the `results` table that have a detection condition (ex. \"not detected\").  This eliminates nondetects, which will inhereantly bias the data, as it is not considering values below the detection levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = results[pd.isnull(results['DetectCond'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows from the `results` table that have duplicate `SampleId` values and parameters (chemical concentrations, field measurements). The `SampleId` field will be the index for the pivoted table.  Each row in the pivoted table will represent an individual water sample.  The `SampleId` is applied to each parameter that comes from the same water sample.  For example, if I go out to a stream and fill a water bottle and have that analyzed for 4 different parameters (i.e. calcium, magnesium, sodium, and chloride), then each result from the analysis of that water will have the same `SampleId`.  Sometimes we sample a station multiple times, so one `StationId` can have many `SampleId` values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.drop_duplicates(subset=['SampleId','ParAbb'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select results that have more than 50 flow values to plot flow change over time.\n",
    "http://stackoverflow.com/questions/17926273/how-to-count-distinct-values-in-a-column-of-a-pandas-group-by-object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def condfix(x):\n",
    "    if x[1]=='Cond':\n",
    "        if x[2]=='mS/cm':\n",
    "            return x[0]/1000\n",
    "        else:\n",
    "            return x[0]\n",
    "    else:\n",
    "        return x[0]\n",
    "    \n",
    "def condunitfix(x):\n",
    "    if x[1]=='Cond':\n",
    "        if x[0]=='mS/cm':\n",
    "            return 'uS/cm'\n",
    "        else:\n",
    "            return 'uS/cm'\n",
    "    else:\n",
    "        return x[0]\n",
    "\n",
    "def pHfix(x):\n",
    "    if x[1] == 'pH':\n",
    "        if x[0] == 0.0:\n",
    "            return np.nan\n",
    "        elif x[0] >= 14.0:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return x[0]\n",
    "    else:\n",
    "        return x[0]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results['ResultValue'] = results[['ResultValue','ParAbb','Unit']].apply(lambda x: condfix(x),1)\n",
    "results['Unit'] = results[['Unit','ParAbb']].apply(lambda x: condunitfix(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results['ResultValue'] = results[['ResultValue','ParAbb']].apply(lambda x: pHfix(x),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize All Fields by date and count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot the data so that parameters are now columns.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datap = results.pivot(index='SampleId', columns='ParAbb', values='ResultValue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns from the pivot table that are pretty much empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datap.dropna(subset=['SO4','Cond','Temp','TDS','pH'],how='all',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table lost the `StationId` field when it was pivoted, so now we need to add the `StationId` field back on to the table by joining it to the previous results table using the `SampleId` field.  First we parse down the results table to only the information we want to retain, then we join the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resdrop = ['AnalysisDate', 'AnalytMeth', 'AnalytMethId',\n",
    "             'DetectCond', 'LabComments', 'LabName', 'LimitType',\n",
    "             'MDL', 'MDLUnit', 'MethodDescript',\n",
    "             'OrgId', 'OrgName', 'Param', 'ProjectId',\n",
    "             'QualCode', 'ResultComment', 'ResultStatus', 'ResultValue',\n",
    "             'SampComment', 'SampDepth',\n",
    "             'SampDepthRef', 'SampDepthU', 'SampEquip', 'SampFrac',\n",
    "             'SampMedia', 'SampMeth', 'SampMethName', 'SampType',\n",
    "             'Unit', 'ParAbb']\n",
    "resPivot = results.drop(resdrop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datapiv = pd.merge(datap, resPivot, left_index=True, right_on='SampleId',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a `StationId` field, we can add our station data, but only the data that will be useful for plotting our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pivStats = station.drop(['Aquifer', 'ConstDate', 'Depth', 'DepthUnit',\n",
    "                         'HoleDUnit', 'HoleDepth', \n",
    "                         'OrgId', 'StationComment', 'StationName', 'matchid'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datapiv = pd.merge(datapiv, pivStats, left_on='StationId', right_index=True,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datapiv.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#datapiv.to_csv(rootname+\"AllResultsPivot.csv\", chunksize=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Create Table For Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "piperdata = datapiv.dropna(subset = ['Ca','Na','Cl','K','Mg','SO4'],how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Relationship between Bicarbonate and Alkalinity.  Fill in missing bicarbonate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0941152486856753, 20.027751188998934, 0.97224865250018067, 0.0, 0.0025819900883626017)\n"
     ]
    }
   ],
   "source": [
    "piv = piperdata.ix[:,['Alk','HCO3']]\n",
    "piv = piv[(piv.Alk < 5000)&(piv.HCO3 < 5000)]\n",
    "piv = piv[(piv.Alk > 0)&(piv.HCO3 > 0)]\n",
    "piv.dropna(inplace=True)\n",
    "lin = linregress(piv.Alk.values,piv.HCO3.values)\n",
    "print lin\n",
    "piperdata.ix[:,\"HCO3\"] = piperdata.apply(lambda x: x['Alk']*lin[0]+lin[1] if np.isnan(x['HCO3']) else x['HCO3'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "piperdata = piperdata.drop(['Alk','As','CO2','Cu','DO','NaK','PO4'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "piperdata.dropna(subset=['Lat_Y','HCO3'], how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "piperdata = pd.merge(piperdata, StatFreq, on='StationId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = {'Ca':0.04990269, 'Mg':0.082287595, 'Na':0.043497608, 'K':0.02557656, 'Cl':0.028206596, \n",
    "     'HCO3':0.016388838, 'CO3':0.033328223, 'SO4':0.020833333, 'NO2':0.021736513, 'NO3':0.016129032}\n",
    "parList = ['Ca','Mg','Na','K','Cl','HCO3','SO4']\n",
    "\n",
    "\n",
    "def CO3zero(x):\n",
    "    if (np.isnan(x)):\n",
    "        return 0.0\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def chrgbal(x):\n",
    "    cation = (x[0]*d['Na'] + x[1]*d['K'] + x[2]*d['Mg'] + x[3]*d['Ca'])\n",
    "    anion = (x[4]*d['Cl'] + x[5]*d['HCO3'] + x[6]*d['CO3'] + x[7]*d['SO4']) \n",
    "    return  (cation - anion)/(cation+anion)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "piperdata['CO3'] = piperdata['CO3'].apply(lambda x: CO3zero(x),1)\n",
    "piperdata['chrgbal'] = piperdata[['Na','K','Mg','Ca','Cl','HCO3','CO3','SO4']].apply(lambda x: chrgbal(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for par in parList:\n",
    "    piperdata[par+\"_mql\"] = piperdata[par].apply(lambda x: x*d[par],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "piperdata = piperdata[abs(piperdata['chrgbal']) < 5.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "piperdata.to_csv(rootname+\"PiperData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FmType</th>\n",
       "      <th>amin</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>amax</th>\n",
       "      <th>std</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blackhawk Formation of Mesaverde Group</td>\n",
       "      <td>0.082288</td>\n",
       "      <td>3.260768</td>\n",
       "      <td>2.057190</td>\n",
       "      <td>20.818762</td>\n",
       "      <td>3.955505</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Castlegate Sandstone of Mesaverde Group</td>\n",
       "      <td>0.246863</td>\n",
       "      <td>1.438841</td>\n",
       "      <td>0.983337</td>\n",
       "      <td>5.126517</td>\n",
       "      <td>0.993381</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ferron Sandstone Member of Mancos Shale</td>\n",
       "      <td>0.049373</td>\n",
       "      <td>13.169177</td>\n",
       "      <td>1.398889</td>\n",
       "      <td>172.803950</td>\n",
       "      <td>29.319353</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flagstaff Limestone (Eocene-Paleocene)</td>\n",
       "      <td>0.493726</td>\n",
       "      <td>1.891047</td>\n",
       "      <td>1.892615</td>\n",
       "      <td>4.854968</td>\n",
       "      <td>0.918245</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mancos Shale</td>\n",
       "      <td>1.234314</td>\n",
       "      <td>33.615775</td>\n",
       "      <td>31.916065</td>\n",
       "      <td>289.693478</td>\n",
       "      <td>45.818120</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>North Horn Formation (Paleocene-Upper Cretaceous)</td>\n",
       "      <td>0.419667</td>\n",
       "      <td>2.233751</td>\n",
       "      <td>2.083110</td>\n",
       "      <td>9.051635</td>\n",
       "      <td>0.920424</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Price River Formation of Mesaverde Group</td>\n",
       "      <td>0.255092</td>\n",
       "      <td>2.013465</td>\n",
       "      <td>2.040732</td>\n",
       "      <td>4.196667</td>\n",
       "      <td>0.966609</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Star Point Sandstone of Mesaverde Group</td>\n",
       "      <td>0.246863</td>\n",
       "      <td>2.736842</td>\n",
       "      <td>2.633203</td>\n",
       "      <td>7.323596</td>\n",
       "      <td>1.001837</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Valley Fill</td>\n",
       "      <td>1.316602</td>\n",
       "      <td>52.690778</td>\n",
       "      <td>13.020366</td>\n",
       "      <td>409.792223</td>\n",
       "      <td>87.194342</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              FmType      amin       mean  \\\n",
       "0             Blackhawk Formation of Mesaverde Group  0.082288   3.260768   \n",
       "1            Castlegate Sandstone of Mesaverde Group  0.246863   1.438841   \n",
       "2            Ferron Sandstone Member of Mancos Shale  0.049373  13.169177   \n",
       "3             Flagstaff Limestone (Eocene-Paleocene)  0.493726   1.891047   \n",
       "4                                       Mancos Shale  1.234314  33.615775   \n",
       "5  North Horn Formation (Paleocene-Upper Cretaceous)  0.419667   2.233751   \n",
       "6           Price River Formation of Mesaverde Group  0.255092   2.013465   \n",
       "7            Star Point Sandstone of Mesaverde Group  0.246863   2.736842   \n",
       "8                                        Valley Fill  1.316602  52.690778   \n",
       "\n",
       "      median        amax        std  size  \n",
       "0   2.057190   20.818762   3.955505   706  \n",
       "1   0.983337    5.126517   0.993381    78  \n",
       "2   1.398889  172.803950  29.319353   108  \n",
       "3   1.892615    4.854968   0.918245    42  \n",
       "4  31.916065  289.693478  45.818120    35  \n",
       "5   2.083110    9.051635   0.920424   578  \n",
       "6   2.040732    4.196667   0.966609    95  \n",
       "7   2.633203    7.323596   1.001837    76  \n",
       "8  13.020366  409.792223  87.194342   261  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piperdata.groupby('FmType')['Mg_mql'].agg([np.min, np.mean, np.median, np.max, np.std, np.size]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FmType\n",
      "Blackhawk Formation of Mesaverde Group               114\n",
      "Castlegate Sandstone of Mesaverde Group               27\n",
      "Ferron Sandstone Member of Mancos Shale               40\n",
      "Flagstaff Limestone (Eocene-Paleocene)                34\n",
      "Mancos Shale                                           7\n",
      "North Horn Formation (Paleocene-Upper Cretaceous)    147\n",
      "Price River Formation of Mesaverde Group              45\n",
      "Star Point Sandstone of Mesaverde Group               27\n",
      "Valley Fill                                           35\n",
      "Name: StationId, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StationType\n",
       "Lake       45\n",
       "Other      25\n",
       "Spring    508\n",
       "Stream    508\n",
       "Well      175\n",
       "Name: StationId, dtype: int64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print piperdata.groupby('FmType')['StationId'].nunique()\n",
    "piperdata.groupby('StationType')['StationId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = list(set(list(piperdata.columns)) - set(['SampleDate', 'SampleId', 'StationId', 'FmType', 'Lat_Y', \n",
    "                                          'Lon_X', 'OrgName', 'StationType','DEM','HorCollMet','PLSS','USGSCAD',\n",
    "                                              'UNITNAME', 'Elev', 'MAP_UNIT_SYMBOL', u'HUC_12', u'HUC_10',\n",
    "                                              'Depth', u'OBJECTID', u'ElevUnit',u'HU_12_NAME',u'HU_10_NAME', u'FmNum']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FmType</th>\n",
       "      <th>FmNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flagstaff Limestone (Eocene-Paleocene)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paleozoic Erathem</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>North Horn Formation (Paleocene-Upper Cretaceous)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Valley Fill</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ferron Sandstone Member of Mancos Shale</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Green River Formation</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Blackhawk Formation of Mesaverde Group</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mancos Shale</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Castlegate Sandstone of Mesaverde Group</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Price River Formation of Mesaverde Group</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Star Point Sandstone of Mesaverde Group</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               FmType  FmNum\n",
       "0              Flagstaff Limestone (Eocene-Paleocene)      8\n",
       "1                                   Paleozoic Erathem      0\n",
       "2   North Horn Formation (Paleocene-Upper Cretaceous)      7\n",
       "3                                         Valley Fill      9\n",
       "4             Ferron Sandstone Member of Mancos Shale      2\n",
       "5                               Green River Formation     10\n",
       "6              Blackhawk Formation of Mesaverde Group      4\n",
       "7                                        Mancos Shale      1\n",
       "8             Castlegate Sandstone of Mesaverde Group      5\n",
       "9            Price River Formation of Mesaverde Group      6\n",
       "10            Star Point Sandstone of Mesaverde Group      3"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forms = pd.DataFrame(fmdict.items(),columns=['FmType','FmNum'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?pd.merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ca_mql', 'NH3_N', 'Na', 'pH', 'TSS', 'NO2', 'NO3', 'HCO3', 'HCO3_mql', 'Fe', 'SO4_mql', 'Cl_mql', 'K_mql', 'Mg', 'Temp', 'Mg_mql', 'K', 'N', 'Q', 'Si', 'SO4', 'Turb', 'CO3', 'Cl', 'Ca', 'Hard', 'Cond', 'Na_mql', 'TDS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\ArcGIS10.3\\lib\\site-packages\\IPython\\kernel\\__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "names = list(set(list(piperdata.columns)) - set(['SampleDate', 'SampleId', 'StationId', 'FmType', 'Lat_Y', \n",
    "                                          'Lon_X', 'OrgName', 'StationType','DEM','HorCollMet','PLSS','USGSCAD',\n",
    "                                              'UNITNAME', 'Elev', 'MAP_UNIT_SYMBOL', u'HUC_12', u'HUC_10',\n",
    "                                              'Depth', u'OBJECTID', u'ElevUnit',u'HU_12_NAME',u'HU_10_NAME', u'FmNum',\n",
    "                                                'count_nonzero','chrgbal']))\n",
    "print names\n",
    "\n",
    "rc('font', family='Arial')\n",
    "pdf = PdfPages(rootname+'pipergeoboxes.pdf')\n",
    "j = {}\n",
    "\n",
    "for i in range(len(names)):\n",
    "    fms = piperdata[[names[i],'FmNum','FmType']]\n",
    "    fms.dropna(inplace=True)\n",
    "    fms = fms[~fms['FmType'].isin([' ','', np.nan, 'Green River Formation', 'Rock Springs Formation of Mesaverde Group', \n",
    "                                   'Holocene Alluvium', 'Masuk Member of Mancos Shale', \n",
    "                                   'Tununk Shale Member of Mancos Shale', 'Blue Gate Shale Member of Mancos Shale', \n",
    "                                   'Emery Sandstone Member of Mancos Shale', 'Pleistocene Series', \n",
    "                             'Paleozoic Erathem', 'Mancos Shale'])]\n",
    "    if len(fms)>30:\n",
    "        j[names[i]] = fms.groupby('FmNum')[names[i]].agg([np.min, np.mean, np.median, np.max, np.std, np.size]).reset_index()\n",
    "        j[names[i]] = pd.merge(j[names[i]],Forms, left_on='FmNum', right_on='FmNum',how='left')\n",
    "        labs = [str(j[names[i]]['FmType'][b]) + \" (n=\" + str(int(j[names[i]]['size'][b])) + \")\" for b in range(len(j[names[i]][va]))]\n",
    "        tickloc = [b+1 for b in range(len(j[names[i]][va]))]\n",
    "        ax = fms.boxplot(column=names[i], by='FmNum', vert=False)\n",
    "        try:\n",
    "            plt.title(ParAbb.keys()[ParAbb.values().index(names[i])])\n",
    "        except(ValueError):\n",
    "            plt.title(names[i])\n",
    "        plt.suptitle('')\n",
    "        plt.yticks(tickloc, labs)\n",
    "        fig = ax.get_figure()\n",
    "        if ParUnAbb.get(names[i],'') == '':\n",
    "            units = names[i]\n",
    "        else:\n",
    "            units = u'%s (%s)'%(names[i],ParUnAbb.get(names[i]))\n",
    "        plt.xlabel(units)     \n",
    "        if np.max(fms[names[i]].values) > 100:\n",
    "            plt.xscale('log')  \n",
    "        plt.tight_layout()      \n",
    "        pdf.savefig(fig)\n",
    "        plt.close()\n",
    "pdf.close()\n",
    "parsum = pd.concat(j)\n",
    "parsum.to_csv(rootname + \"geology_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ca_mql', 'NH3_N', 'Na', 'pH', 'TSS', 'NO2', 'NO3', 'HCO3', 'HCO3_mql', 'Fe', 'SO4_mql', 'Cl_mql', 'count_nonzero', 'K_mql', 'Mg', 'Temp', 'Mg_mql', 'K', 'N', 'Q', 'Si', 'SO4', 'Turb', 'CO3', 'Cl', 'Ca', 'Hard', 'Cond', 'Na_mql', 'TDS', 'chrgbal']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\ArcGIS10.3\\lib\\site-packages\\IPython\\kernel\\__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "names = list(set(list(piperdata.columns)) - set(['SampleDate', 'SampleId', 'StationId', 'FmType', 'Lat_Y', \n",
    "                                          'Lon_X', 'OrgName', 'StationType','DEM','HorCollMet','PLSS','USGSCAD',\n",
    "                                              'UNITNAME', 'Elev', 'MAP_UNIT_SYMBOL', u'HUC_12', u'HUC_10',\n",
    "                                              'Depth', u'OBJECTID', u'ElevUnit',u'HU_12_NAME',u'HU_10_NAME', \n",
    "                                                 u'FmNum', u'FmNum',\n",
    "                                                'count_nonzero','chrgbal']))\n",
    "print names\n",
    "\n",
    "pipersprings = piperdata[piperdata['StationType']=='Spring']\n",
    "\n",
    "rc('font', family='Arial')\n",
    "pdf = PdfPages(rootname+'piperspringsgeoboxes.pdf')\n",
    "j = {}\n",
    "\n",
    "for i in range(len(names)):\n",
    "    fms = pipersprings[[names[i],'FmNum']]\n",
    "    fms.dropna(inplace=True)\n",
    "    fms = fms[~fms[va].isin([' ','', np.nan, 'Green River Formation', 'Rock Springs Formation of Mesaverde Group', \n",
    "                                   'Holocene Alluvium', 'Masuk Member of Mancos Shale', \n",
    "                                   'Tununk Shale Member of Mancos Shale', 'Blue Gate Shale Member of Mancos Shale', \n",
    "                                   'Emery Sandstone Member of Mancos Shale', 'Pleistocene Series', 'Paleozoic Erathem',\n",
    "                             'Mancos Shale', 'Ferron Sandstone Member of Mancos Shale'])]\n",
    "    if len(fms)>30:\n",
    "        j[names[i]] = fms.groupby('FmNum')[names[i]].agg([np.min, np.mean, np.median, np.max, np.std, np.size]).reset_index()\n",
    "        j[names[i]] = pd.merge(j[names[i]],Forms, left_on='FmNum', right_on='FmNum',how='left')\n",
    "        labs = [str(j[names[i]]['FmType'][b]) + \" (n=\" + str(int(j[names[i]]['size'][b])) + \")\" for b in range(len(j[names[i]][va]))]\n",
    "        tickloc = [b+1 for b in range(len(j[names[i]][va]))]\n",
    "        ax = fms.boxplot(column=names[i], by='FmNum', vert=False)\n",
    "        try:\n",
    "            plt.title(ParAbb.keys()[ParAbb.values().index(names[i])])\n",
    "        except(ValueError):\n",
    "            plt.title(names[i])\n",
    "        plt.suptitle('')\n",
    "        plt.yticks(tickloc, labs)\n",
    "        fig = ax.get_figure()\n",
    "        if ParUnAbb.get(names[i],'') == '':\n",
    "            units = names[i]\n",
    "        else:\n",
    "            units = u'%s (%s)'%(names[i],ParUnAbb.get(names[i]))\n",
    "        plt.xlabel(units)     \n",
    "        if np.max(fms[names[i]].values) > 100:\n",
    "            plt.xscale('log')  \n",
    "        plt.tight_layout()      \n",
    "        pdf.savefig(fig)\n",
    "        plt.close()\n",
    "pdf.close()\n",
    "parsum = pd.concat(j)\n",
    "parsum.to_csv(rootname + \"springs_geology_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\ArcGIS10.3\\lib\\site-packages\\IPython\\kernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "pdf = PdfPages(rootname+'hucboxes.pdf')\n",
    "j = {}\n",
    "for i in range(len(names)):\n",
    "    hucs = datapiv[[names[i],'HU_10_NAME']]\n",
    "    hucs.dropna(inplace=True)\n",
    "    hucs = hucs[~hucs['HU_10_NAME'].isin([' ','', np.nan, 'Spanish Fork Creek',\n",
    "                                          'Twelvemile Creek','Chicken Creek','North Salt Wash', 'West Creek'])]\n",
    "    if len(hucs)>30:\n",
    "        j[names[i]] = hucs.groupby('HU_10_NAME')[names[i]].agg([np.min, np.mean, np.median, np.max, np.std, np.size]).reset_index()\n",
    "        labs = [str(j[names[i]]['HU_10_NAME'][b]) + \" (n=\" + str(int(j[names[i]]['size'][b])) + \")\" for b in range(len(j[names[i]]['HU_10_NAME']))]\n",
    "        tickloc = [b+1 for b in range(len(j[names[i]]['HU_10_NAME']))]              \n",
    "        ax = hucs.boxplot(column=names[i],by='HU_10_NAME',vert=False)\n",
    "        plt.suptitle('')\n",
    "        plt.title(ParAbb.keys()[ParAbb.values().index(names[i])])\n",
    "        plt.yticks(tickloc, labs)\n",
    "        fig = ax.get_figure() \n",
    "        if ParUnAbb.get(names[i],'') == '':\n",
    "            units = names[i]\n",
    "        else:\n",
    "            units = names[i] +' (' + u'%s'% (ParUnAbb.get(names[i])) +')'\n",
    "        plt.xlabel(units) \n",
    "        if np.max(hucs[names[i]].values) > 100:\n",
    "            plt.xscale('log')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        pdf.savefig(fig)\n",
    "        plt.close()\n",
    "pdf.close()\n",
    "parsum = pd.concat(j)\n",
    "parsum.to_csv(rootname + \"stream_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datapivcor = datapiv.dropna(subset=['TDS','Q'],how='any')\n",
    "datapivcor = datapivcor[datapivcor['Q']>1]\n",
    "datapivcor = datapivcor[datapivcor['TDS']<10000]\n",
    "datapivcor = datapivcor[datapivcor['StationType'].isin(['Stream','Spring'])]\n",
    "pdf = PdfPages(rootname+'Q_TDS.pdf')\n",
    "\n",
    "for key, grp in datapivcor.groupby(['StationId']):\n",
    "    lin = linregress(grp['Q'],grp['TDS'])\n",
    "    if len(grp) > 3:\n",
    "        if lin[2]>0.5:\n",
    "            fig = plt.figure()\n",
    "            plt.scatter(x=grp['Q'],y= grp['TDS'], label=key)\n",
    "            plt.title(str(key) + ' ' +str(grp['StationType'].values[0]))\n",
    "            plt.xlabel('Discharge (gpm)')\n",
    "            plt.ylabel('TDS (mg/L)')\n",
    "            plt.legend(loc='best')    \n",
    "            pdf.savefig(fig)\n",
    "            plt.close()\n",
    "pdf.close()\n",
    "    \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
