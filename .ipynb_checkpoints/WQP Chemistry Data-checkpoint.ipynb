{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import dtype\n",
    "import matplotlib.pyplot as plt\n",
    "#from pylab import rcParams\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "#%matplotlib inline\n",
    "#rcParams['figure.figsize'] = 15, 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOGM Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utah Division of Oil Gas and Mining (DOGM) data derived from the <a href=http://linux1.ogm.utah.gov/WebStuff/wwwroot/wqdb.html>DOGM website</a>. Station information obtained from digitization of PDF maps provided by mining companies to DOGM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ubuntu rootname = \"/media/p/5F5B-8FCB/PROJECTS/MLSNF/Data/CHEM/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rootname = \"E:/PROJECTS/MLSNF/Data/CHEM/\"\n",
    "rootname = \"U:/GWP/Groundwater/UMSS_Manti/Data/\"\n",
    "#rootname = \"/media/p/5F5B-8FCB/PROJECTS/MLSNF/Data/CHEM/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOGM = rootname + \"DOGM/UDOGM_allResults.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOGM_ST = rootname + \"DOGM/UDOGM_Station.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and Prepare DOGM Results Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parmatch = {\"ACIDITY AS CACO3\":\"Acidity\", \"TOTAL ALKALINITY AS CACO3\":\"Alkalinity, total\", \n",
    "            \"DISSOLVED ALUMINUM\":\"Aluminum\", \"TOTAL ALUMINUM\":\"Aluminum\", \"AMMONIA AS N\":\"Ammonia-nitrogen as N\", \n",
    "            \"DISSOLVED ARSENIC\":\"Arsenic\", \"TOTAL ARSENIC\":\"Arsenic\", \"DISSOLVED BARIUM\":\"Barium\", \n",
    "            \"TOTAL BARIUM\":\"Barium\", \"TOTAL BERYLLIUM\":\"Beryllium\", \"BICARBONATE AS HCO3\":\"Bicarbonate\", \n",
    "            \"B.O.D. 5, MG/L\":\"Biochemical oxygen demand, standard conditions\", \"DISSOLVED BORON\":\"Boron\", \n",
    "            \"TOTAL BORON\":\"Boron\", \"BROMIDE\":\"Bromide\", \"DISSOLVED CADMIUM\":\"Cadmium\", \"TOTAL CADMIUM\":\"Cadmium\", \n",
    "            \"DISSOLVED CALCIUM\":\"Calcium\", \"TOTAL CALCIUM\":\"Calcium\", \"CARBONATE AS CO3\":\"Carbonate\", \n",
    "            \"C.O.D., MG/L\":\"Chemical oxygen demand\", \"CHLORIDE\":\"Chloride\", \"DISSOLVED CHROMIUM\":\"Chromium\", \n",
    "            \"TOTAL CHROMIUM\":\"Chromium\", \"CHROMIUM HEX, CR\":\"Chromium(VI)\", \"TOTAL COBALT\":\"Cobalt\", \n",
    "            \"SP. CONDUCTIVITY (FIELD)\":\"Conductivity\", \"SPECIFIC CONDUCTIVITY (LAB)\":\"Conductivity\", \n",
    "            \"DISSOLVED COPPER\":\"Copper\", \"TOTAL COPPER\":\"Copper\", \"CYANIDE\":\"Cyanide\", \"DEPTH\":\"Depth\", \n",
    "            \"DISSOLVED OXYGEN (FIELD)\":\"Dissolved oxygen (DO)\", \"FLOW\":\"Flow\", \"FLUORIDE\":\"Fluoride\", \n",
    "            \"TOTAL HARDNESS AS CACO3\":\"Hardness, Ca, Mg\", \"HYDROXIDE\":\"Hydroxide\", \"DISSOLVED IRON\":\"Iron\", \n",
    "            \"TOTAL IRON\":\"Iron\", \"TOTAL KIELDAHL NITROGEN, T.K.N.\":\"Kjeldahl nitrogen\", \"DISSOLVED LEAD\":\"Lead\", \n",
    "            \"TOTAL LEAD\":\"Lead\", \"DISSOLVED MAGNESIUM\":\"Magnesium\", \"TOTAL MAGNESIUM\":\"Magnesium\", \n",
    "            \"DISSOLVED MANGANESE\":\"Manganese\", \"TOTAL MANGANESE\":\"Manganese\", \"DISSOLVED MERCURY\":\"Mercury\", \n",
    "            \"TOTAL MERCURY\":\"Mercury\", \"DISSOLVED MOLYBDENUM\":\"Molybdenum\", \"TOTAL MOLYBDENUM\":\"Molybdenum\", \n",
    "            \"DISSOLVED NICKEL\":\"Nickel\", \"TOTAL NICKEL\":\"Nickel\", \"DISSOLVED NITRATE, NO3\":\"Nitrate\", \n",
    "            \"NITRATE AS N\":\"Nitrate as N\", \"DISSOLVED NITRITE, NO2\":\"Nitrite\", \"NITRITE AS N\":\"Nitrogen\", \n",
    "            \"NO2+NO3 AS N\":\"Nitrogen\", \"DISSOLVED ORTHO PHOSPH, OPO4\":\"Orthophosphate\", \n",
    "            \"ORTHO. PHOSPHATE\":\"Orthophosphate\", \"PH (FIELD)\":\"pH\", \"PH (LAB)\":\"pH, lab\", \n",
    "            \"TOTAL PHOSPHORUS\":\"Phosphorus\", \"DISSOLVED POTASSIUM\":\"Potassium\", \"DISSOLVED SELENIUM\":\"Selenium\", \n",
    "            \"TOTAL SELENIUM\":\"Selenium\", \"DISSOLVED SILICA, SIO2\":\"Silica\", \"DISSOLVED SILVER\":\"Silver\", \n",
    "            \"TOTAL SILVER\":\"Silver\", \"DISSOLVED SODIUM\":\"Sodium\", \"TOTAL SODIUM\":\"Sodium\", \n",
    "            \"SODIUM ADSORPTION RATIO\":\"Sodium adsorption ratio\", \"SULFATE\":\"Sulfate\", \"SULFIDE\":\"Sulfide\", \n",
    "            \"TOTAL ANIONS\":\"Sum of anions\", \"TOTAL CATIONS\":\"Sum of cations\", \n",
    "            \"AIR TEMPERATURE (FIELD)\":\"Temperature, air\", \"FIELD WATER TEMPERATURE\":\"Temperature, water\", \n",
    "            \"TOTAL DISSOLVED SOLIDS, @ 180 C\":\"Total dissolved solids\", \n",
    "            \"TOTAL SUSPENDED SOLIDS\":\"Total suspended solids\", \"TURBIDITY (FIELD)\":\"Turbidity\", \n",
    "            \"TURBIDITY (LAB)\":\"Turbidity\", \"TOTAL VANADIUM\":\"Vanadium\", \"DISSOLVED ZINC\":\"Zinc\", \"TOTAL ZINC\":\"Zinc\"} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dogtypes = {'Unnamed: 0':dtype('int8'),'MIN_DET': dtype('float32'), 'MINE_ID': dtype('int8'), \n",
    "            'ANAL_NAME': dtype('str_'), 'PARAM_ID': dtype('int8'), 'SAMPLE_ID': dtype('str_'), 'SITE_NAME': dtype('str_'), \n",
    "            'METHD': dtype('str_'), 'DATE_REC': dtype('str_'),'EQUALITY': dtype('str_'), 'TIME_ANAL': dtype('str_'), \n",
    "            'STATION_ID': dtype('str_'), 'PAR_DESC': dtype('str_'), 'PAR_ABB': dtype('str_'), 'ANAL_METHD': dtype('str_'), \n",
    "            'METH_DESC': dtype('str_'), 'SAMP_TYPE': dtype('str_'), 'LAB_ID': dtype('str_'), 'MINE_NAME': dtype('str_'), \n",
    "            'SITE_DESC': dtype('str_'), 'SITE_ID': dtype('int8'), 'VALUE': dtype('float32'), 'PERM_NO': dtype('str_'), \n",
    "            'LAB_NAME': dtype('str_'), 'UNITS': dtype('str_'), 'SAMP_DESC': dtype('str_'), 'DATE_ANAL': dtype('str_'), \n",
    "            'SITE_TYPE': dtype('str_'), 'LAB_CODE': dtype('str_'), 'SAMPLR_NAM': dtype('str_'), 'COMMENTS': dtype('str_')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dogmr = pd.read_csv(DOGM, dtype=dogtypes, parse_dates=[11,14,15,19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DResCols = {\"ANAL_METHD\":\"AnalytMeth\", \"ANAL_NAME\":\"Param\", \"COMMENTS\":\"ResultComment\", \"DATE_ANAL\":\"AnalysisDate\", \n",
    "            \"DATETIME_SAMP\":\"SampleDate\", \"EQUALITY\":\"DetectCond\", \"LAB_CODE\":\"LabComments\", \"LAB_NAME\":\"LabName\", \n",
    "            \"METH_DESC\":\"MethodDescript\", \"METHD\":\"SampMeth\", \"MIN_DET\":\"MDL\", \"SAMP_TYPE\":\"SampMethName\", \n",
    "            \"SAMPLE_ID\":\"SampleId\", \"STATION_ID\":\"StationId\", \"UNITS\":\"Unit\", \"VALUE\":\"ResultValue\"} \n",
    "dogmr.rename(columns=DResCols,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dogmr['Param'] = dogmr['PAR_DESC'].apply(lambda x: parmatch.get(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dogmr.dropna(how='any',subset=['StationId'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dogmr.drop(['PARAM_ID','SAMPLR_NAM','SITE_ID','SITE_DESC','PAR_DESC','TIME_ANAL','DATE_RPT',\n",
    "            'DATE_REC','Unnamed: 0', 'LAB_ID','MINE_ID','PAR_ABB','MINE_NAME', 'SITE_NAME', 'SAMP_DESC',\n",
    "            'PERM_NO','SITE_TYPE'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dogmr.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Import and Prepare DOGM Station Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dogms = pd.read_csv(DOGM_ST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dogms.columns\n",
    "dogms['StationComment'] = dogms[['StationComment','DESCRIPT']].apply(lambda x: x[0] if \n",
    "                                                                     (x[1])==np.nan else \n",
    "                                                                     str(x[0])+';'+str(x[1]),1)\n",
    "dogms.drop(['DESCRIPT'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##WQP Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data downloaded from the <a href=http://waterqualitydata.us/portal/>Water Quality Portal (WQP)</a> on 7/22/2015. <br>\n",
    "<b>Stations:</b><br>\n",
    "http://waterqualitydata.us/Station/search?sampleMedia=Water&characteristicType=Information%3BInorganics%2C+Major%2C+Metals%3BInorganics%2C+Major%2C+Non-metals%3BInorganics%2C+Minor%2C+Metals%3BInorganics%2C+Minor%2C+Non-metals%3BNot+Assigned%3BNutrient%3BPhysical%3BStable+Isotopes&bBox=-111.68%2C38.8%2C-111%2C40&mimeType=csv&zip=yes&sorted=no <br>\n",
    "<b>Results:</b><br>\n",
    "http://waterqualitydata.us/Result/search?sampleMedia=Water&characteristicType=Information%3BInorganics%2C+Major%2C+Metals%3BInorganics%2C+Major%2C+Non-metals%3BInorganics%2C+Minor%2C+Metals%3BInorganics%2C+Minor%2C+Non-metals%3BNot+Assigned%3BNutrient%3BPhysical%3BStable+Isotopes&bBox=-111.68%2C38.8%2C-111%2C40&mimeType=csv&zip=yes&sorted=no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define data location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "station = rootname + \"WQP/Station.csv\"\n",
    "result = rootname +\"WQP/Result.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Results Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map data types for data to be imported and designate columns to convert to datetimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rdtypes = {\"OrganizationIdentifier\":np.str_, \"OrganizationFormalName\":np.str_, \"ActivityIdentifier\":np.str_, \n",
    "           \"ActivityTypeCode\":np.str_, \"ActivityMediaName\":np.str_, \"ActivityMediaSubdivisionName\":np.str_, \n",
    "           \"ActivityStartDate\":np.str_, \"ActivityStartTime/Time\":np.str_, \"ActivityStartTime/TimeZoneCode\":np.str_, \n",
    "           \"ActivityEndDate\":np.str_, \"ActivityEndTime/Time\":np.str_, \"ActivityEndTime/TimeZoneCode\":np.str_, \n",
    "           \"ActivityDepthHeightMeasure/MeasureValue\":np.float16, \"ActivityDepthHeightMeasure/MeasureUnitCode\":np.str_, \n",
    "           \"ActivityDepthAltitudeReferencePointText\":np.str_, \"ActivityTopDepthHeightMeasure/MeasureValue\":np.float16, \n",
    "           \"ActivityTopDepthHeightMeasure/MeasureUnitCode\":np.str_, \n",
    "           \"ActivityBottomDepthHeightMeasure/MeasureValue\":np.float16, \n",
    "           \"ActivityBottomDepthHeightMeasure/MeasureUnitCode\":np.str_, \n",
    "           \"ProjectIdentifier\":np.str_, \"ActivityConductingOrganizationText\":np.str_, \n",
    "           \"MonitoringLocationIdentifier\":np.str_, \"ActivityCommentText\":np.str_, \n",
    "           \"SampleAquifer\":np.str_, \"HydrologicCondition\":np.str_, \"HydrologicEvent\":np.str_, \n",
    "           \"SampleCollectionMethod/MethodIdentifier\":np.str_, \"SampleCollectionMethod/MethodIdentifierContext\":np.str_, \n",
    "           \"SampleCollectionMethod/MethodName\":np.str_, \"SampleCollectionEquipmentName\":np.str_, \n",
    "           \"ResultDetectionConditionText\":np.str_, \"CharacteristicName\":np.str_, \"ResultSampleFractionText\":np.str_, \n",
    "           \"ResultMeasureValue\":np.str_, \"ResultMeasure/MeasureUnitCode\":np.str_, \"MeasureQualifierCode\":np.str_, \n",
    "           \"ResultStatusIdentifier\":np.str_, \"StatisticalBaseCode\":np.str_, \"ResultValueTypeName\":np.str_, \n",
    "           \"ResultWeightBasisText\":np.str_, \"ResultTimeBasisText\":np.str_, \"ResultTemperatureBasisText\":np.str_, \n",
    "           \"ResultParticleSizeBasisText\":np.str_, \"PrecisionValue\":np.str_, \"ResultCommentText\":np.str_, \n",
    "           \"USGSPCode\":np.str_, \"ResultDepthHeightMeasure/MeasureValue\":np.float16, \n",
    "           \"ResultDepthHeightMeasure/MeasureUnitCode\":np.str_, \"ResultDepthAltitudeReferencePointText\":np.str_, \n",
    "           \"SubjectTaxonomicName\":np.str_, \"SampleTissueAnatomyName\":np.str_, \n",
    "           \"ResultAnalyticalMethod/MethodIdentifier\":np.str_, \"ResultAnalyticalMethod/MethodIdentifierContext\":np.str_, \n",
    "           \"ResultAnalyticalMethod/MethodName\":np.str_, \"MethodDescriptionText\":np.str_, \"LaboratoryName\":np.str_, \n",
    "           \"AnalysisStartDate\":np.str_, \"ResultLaboratoryCommentText\":np.str_, \n",
    "           \"DetectionQuantitationLimitTypeName\":np.str_, \"DetectionQuantitationLimitMeasure/MeasureValue\":np.str_, \n",
    "           \"DetectionQuantitationLimitMeasure/MeasureUnitCode\":np.str_, \"PreparationStartDate\":np.str_, \n",
    "           \"ProviderName\":np.str_} \n",
    "\n",
    "dt = [[6,7],56,61]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import result data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = pd.read_csv(result, dtype=Rdtypes, parse_dates=dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(list(res['CharacteristicName'].unique())).to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remap column names to standards and drop unneeded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ResFieldDict = {\"AnalysisStartDate\":\"AnalysisDate\", \"ResultAnalyticalMethod/MethodIdentifier\":\"AnalytMeth\", \n",
    "                \"ResultAnalyticalMethod/MethodName\":\"AnalytMethId\", \"ResultDetectionConditionText\":\"DetectCond\", \n",
    "                \"ResultLaboratoryCommentText\":\"LabComments\", \"LaboratoryName\":\"LabName\", \n",
    "                \"DetectionQuantitationLimitTypeName\":\"LimitType\", \"DetectionQuantitationLimitMeasure/MeasureValue\":\"MDL\", \n",
    "                \"DetectionQuantitationLimitMeasure/MeasureUnitCode\":\"MDLUnit\", \"MethodDescriptionText\":\"MethodDescript\", \n",
    "                \"OrganizationIdentifier\":\"OrgId\", \"OrganizationFormalName\":\"OrgName\", \"CharacteristicName\":\"Param\", \n",
    "                \"ProjectIdentifier\":\"ProjectId\", \"MeasureQualifierCode\":\"QualCode\", \"ResultCommentText\":\"ResultComment\", \n",
    "                \"ResultStatusIdentifier\":\"ResultStatus\", \"ResultMeasureValue\":\"ResultValue\", \n",
    "                \"ActivityCommentText\":\"SampComment\", \"ActivityDepthHeightMeasure/MeasureValue\":\"SampDepth\", \n",
    "                \"ActivityDepthAltitudeReferencePointText\":\"SampDepthRef\", \n",
    "                \"ActivityDepthHeightMeasure/MeasureUnitCode\":\"SampDepthU\", \"SampleCollectionEquipmentName\":\"SampEquip\", \n",
    "                \"ResultSampleFractionText\":\"SampFrac\", \"ActivityStartDate\":\"SampleDate\", \"ActivityIdentifier\":\"SampleId\", \n",
    "                \"ActivityStartTime/Time\":\"SampleTime\", \"ActivityMediaSubdivisionName\":\"SampMedia\", \n",
    "                \"SampleCollectionMethod/MethodIdentifier\":\"SampMeth\", \"SampleCollectionMethod/MethodName\":\"SampMethName\", \n",
    "                \"ActivityTypeCode\":\"SampType\", \"MonitoringLocationIdentifier\":\"StationId\", \n",
    "                \"ResultMeasure/MeasureUnitCode\":\"Unit\", \"USGSPCode\":\"USGSPCode\",\n",
    "                \"ActivityStartDate_ActivityStartTime/Time\":\"SampleDate\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res.rename(columns=ResFieldDict,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resdroplist = [\"ActivityBottomDepthHeightMeasure/MeasureUnitCode\", \"ActivityBottomDepthHeightMeasure/MeasureValue\", \n",
    "               \"ActivityConductingOrganizationText\", \"ActivityEndDate\", \"ActivityEndTime/Time\", \n",
    "               \"ActivityEndTime/TimeZoneCode\", \"ActivityMediaName\", \"ActivityStartTime/TimeZoneCode\", \n",
    "               \"ActivityTopDepthHeightMeasure/MeasureUnitCode\", \"ActivityTopDepthHeightMeasure/MeasureValue\", \n",
    "               \"HydrologicCondition\", \"HydrologicEvent\", \"PrecisionValue\", \"PreparationStartDate\", \"ProviderName\", \n",
    "               \"ResultAnalyticalMethod/MethodIdentifierContext\", \"ResultDepthAltitudeReferencePointText\", \n",
    "               \"ResultDepthHeightMeasure/MeasureUnitCode\", \"ResultDepthHeightMeasure/MeasureValue\", \n",
    "               \"ResultParticleSizeBasisText\", \"ResultTemperatureBasisText\", \n",
    "               \"ResultTimeBasisText\", \"ResultValueTypeName\", \"ResultWeightBasisText\", \"SampleAquifer\", \n",
    "               \"SampleCollectionMethod/MethodIdentifierContext\", \"SampleTissueAnatomyName\", \"StatisticalBaseCode\", \n",
    "               \"SubjectTaxonomicName\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res.drop(resdroplist,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert string fields to values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res['ResultValue'] = res['ResultValue'].convert_objects(convert_numeric=True)\n",
    "res['MDL'] = res['MDL'].convert_objects(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `_WQX` suffix from `StationID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res['StationId'] = res['StationId'].str.replace('_WQX-','-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(list(res['Unit'].unique())).to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Station Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stat = pd.read_csv(station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map Fields to Standard UGS database format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "StatFieldDict = {\"MonitoringLocationIdentifier\":\"StationId\", \"AquiferName\":\"Aquifer\", \"AquiferTypeName\":\"AquiferType\", \n",
    "             \"ConstructionDateText\":\"ConstDate\", \"CountyCode\":\"CountyCode\", \"WellDepthMeasure/MeasureValue\":\"Depth\", \n",
    "             \"WellDepthMeasure/MeasureUnitCode\":\"DepthUnit\", \"VerticalMeasure/MeasureValue\":\"Elev\", \n",
    "             \"VerticalAccuracyMeasure/MeasureValue\":\"ElevAcc\", \"VerticalAccuracyMeasure/MeasureUnitCode\":\"ElevAccUnit\", \n",
    "             \"VerticalCollectionMethodName\":\"ElevMeth\", \"VerticalCoordinateReferenceSystemDatumName\":\"ElevRef\", \n",
    "             \"VerticalMeasure/MeasureUnitCode\":\"ElevUnit\", \"FormationTypeText\":\"FmType\", \n",
    "             \"WellHoleDepthMeasure/MeasureValue\":\"HoleDepth\", \"WellHoleDepthMeasure/MeasureUnitCode\":\"HoleDUnit\", \n",
    "             \"HorizontalAccuracyMeasure/MeasureValue\":\"HorAcc\", \"HorizontalAccuracyMeasure/MeasureUnitCode\":\"HorAccUnit\", \n",
    "             \"HorizontalCollectionMethodName\":\"HorCollMeth\", \"HorizontalCoordinateReferenceSystemDatumName\":\"HorRef\", \n",
    "             \"HUCEightDigitCode\":\"HUC8\", \"LatitudeMeasure\":\"Lat_Y\", \"LongitudeMeasure\":\"Lon_X\", \n",
    "             \"OrganizationIdentifier\":\"OrgId\", \"OrganizationFormalName\":\"OrgName\", \"StateCode\":\"StateCode\", \n",
    "             \"MonitoringLocationDescriptionText\":\"StationComment\", \"MonitoringLocationName\":\"StationName\", \n",
    "             \"MonitoringLocationTypeName\":\"StationType\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stat.rename(columns=StatFieldDict,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop leftover fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statdroplist = [\"ContributingDrainageAreaMeasure/MeasureUnitCode\", \"ContributingDrainageAreaMeasure/MeasureValue\", \n",
    "                \"DrainageAreaMeasure/MeasureUnitCode\", \"DrainageAreaMeasure/MeasureValue\", \"CountryCode\", \"ProviderName\", \n",
    "                \"SourceMapScaleNumeric\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stat.drop(statdroplist,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `_WQX` suffix from `StationID` and take out duplicate stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stat['StationId'] = stat['StationId'].str.replace('_WQX-','-')\n",
    "stat.drop_duplicates(subset=['StationId'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Combine Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append Results Data Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.concat([res,dogmr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del(res,dogmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ParAbb = {\"Alkalinity\":\"Alk\", \"Alkalinity, Carbonate as CaCO3\":\"Alk\", \"Alkalinity, total\":\"Alk\", \n",
    "          \"Arsenic\":\"As\", \"Calcium\":\"Ca\", \"Chloride\":\"Cl\", \"Carbon dioxide\":\"CO2\", \"Carbonate\":\"CO3\", \n",
    "          \"Carbonate (CO3)\":\"CO3\", \"Specific conductance\":\"Cond\", \"Conductivity\":\"Cond\", \"Copper\":\"Cu\", \n",
    "          \"Depth\":\"Depth\", \"Dissolved oxygen (DO)\":\"DO\", \"Iron\":\"Fe\", \n",
    "          \"Hardness, Ca, Mg\":\"Hard\", \"Total hardness -- SDWA NPDWR\":\"Hard\", \n",
    "          \"Bicarbonate\":\"HCO3\", \"Potassium\":\"K\", \"Magnesium\":\"Mg\", \"Kjeldahl nitrogen\":\"N\", \n",
    "          \"Nitrogen, mixed forms (NH3), (NH4), organic, (NO2) and (NO3)\":\"N\", \"Nitrogen\":\"N\", \"Sodium\":\"Na\", \n",
    "          \"Sodium plus potassium\":\"NaK\", \"Ammonia-nitrogen\":\"NH3_N\", \"Ammonia-nitrogen as N\":\"NH3_N\", \"Nitrite\":\"NO2\", \n",
    "          \"Nitrate\":\"NO3\", \"Nitrate as N\":\"NO3_N\", \"pH\":\"pH\", \"pH, lab\":\"pH\", \"Phosphate-phosphorus\":\"PO4\", \n",
    "          \"Orthophosphate\":\"PO4\", \"Phosphate\":\"PO4\", \"Stream flow, instantaneous\":\"Q\", \"Flow\":\"Q\", \n",
    "          \"Flow rate, instantaneous\":\"Q\", \"Silica\":\"Si\", \"Sulfate\":\"SO4\", \"Sulfate as SO4\":\"SO4\", \n",
    "          \"Total dissolved solids\":\"TDS\", \"Temperature, water\":\"Temp\", \n",
    "          \"Total suspended solids\":\"TSS\", \"Turbidity\":\"Turb\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results['ParAbb'] = results['Param'].apply(lambda x: ParAbb.get(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del results['USGSPCode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#results.to_csv(rootname+\"AllResults.csv\", chunksize=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stat.set_index(['StationId'],inplace=True)\n",
    "dogms.set_index(['StationId'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station = pd.concat([stat,dogms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station[\"index\"] = station.index\n",
    "station.drop_duplicates(subset='index', take_last=False, inplace=True)\n",
    "del station[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(stat,dogms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "station.drop(['AquiferType','UTM_X','UTM_Y','SITE_ID','OBJECTID','HUC8','MINE_ID','ElevMeth','Elev','ElevAcc',\n",
    "              'ElevRef','ElevUnit','HorAcc', 'HorAccUnit','StateCode',\n",
    "              'ElevAccUnit','HorRef','CountyCode'], inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "station.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stattype = {\"Stream: Ditch\":\"Stream\", \"Stream\":\"Stream\", \"Well\":\"Well\", \"Spring\":\"Spring\", \n",
    "            \"Stream: Canal\":\"Stream\", \"Subsurface: Tunnel, shaft, or mine\":\"Mine Drain\", \n",
    "            \"Well: Test hole not completed as a well\":\"Well\", \"Subsurface: Groundwater drain\":\"Mine Drain\", \n",
    "            \"Lake, Reservoir, Impoundment\":\"Lake\", \"River/Stream\":\"Stream\", \"Lake\":\"Lake\", \"Facility Other\":\"Other\", \n",
    "            \"Canal Drainage\":\"Stream\", \"Canal Irrigation\":\"Stream\", \"MD\":\"Mine Drain\", \"SW\":\"Stream\", \"GW\":\"Well\", \n",
    "            \"SP\":\"Spring\", \"UPDES Permit discharge point\":\"Mine Drain\", \"Lake; Sediment Pond; Stagnant water\":\"Lake\", \n",
    "            \"Other\":\"Other\", \"CG-2\":\"Other\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "station['StationType'] = station['StationType'].apply(lambda x: stattype.get(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#station.to_csv(rootname + \"AllStations.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Merge Station and Results Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#complete = pd.merge(results, station, left_on = \"StationId\", right_index=True, how=\"left\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#complete.to_csv(rootname + \"AllChemData.csv\", chunksize=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Pivot Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows from the `results` table that have null `SampleId` values or parameter abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.dropna(subset=['SampleId','ParAbb'],how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows from the `results` table that have a detection condition (ex. \"not detected\").  This eliminates nondetects, which will inhereantly bias the data, as it is not considering values below the detection levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = results[pd.isnull(results['DetectCond'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows from the `results` table that have duplicate `SampleId` values and parameters (chemical concentrations, field measurements). The `SampleId` field will be the index for the pivoted table.  Each row in the pivoted table will represent an individual water sample.  The `SampleId` is applied to each parameter that comes from the same water sample.  For example, if I go out to a stream and fill a water bottle and have that analyzed for 4 different parameters (i.e. calcium, magnesium, sodium, and chloride), then each result from the analysis of that water will have the same `SampleId`.  Sometimes we sample a station multiple times, so one `StationId` can have many `SampleId` values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.drop_duplicates(subset=['SampleId','ParAbb'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select results that have more than 50 flow values to plot flow change over time.\n",
    "http://stackoverflow.com/questions/17926273/how-to-count-distinct-values-in-a-column-of-a-pandas-group-by-object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fieldsummary = results.groupby(['StationId','Param'])['ResultValue'].nunique().reset_index()\n",
    "fieldsummary = fieldsummary[fieldsummary['ResultValue']>50]\n",
    "manyQs = fieldsummary[fieldsummary['Param']=='Flow']\n",
    "manyDs = fieldsummary[fieldsummary['Param']=='Depth']\n",
    "manyQsStats = list(manyQs['StationId'].values)\n",
    "manyDsStats = list(manyDs['StationId'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize All Fields by date and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "durationsummary = results.groupby(['StationId','Param'])['SampleDate'].agg([np.min,np.max,np.size]).reset_index()\n",
    "durationsummary.convert_objects(convert_numeric=True)\n",
    "print list(durationsummary.columns)\n",
    "durationsummary['amax'] =  durationsummary['amax'].apply(lambda x: str(x).replace('nan','00:00:00'),1)\n",
    "durationsummary['amin'] =  durationsummary['amin'].apply(lambda x: str(x).replace('nan','00:00:00'),1)\n",
    "durationsummary['duration'] = durationsummary['amax'].astype(np.datetime64) - durationsummary['amin'].astype(np.datetime64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "durationsummary.to_csv(rootname + \"fieldsummaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LongFlow = durationsummary[(durationsummary['Param']=='Flow') & (durationsummary['size']>50) & \n",
    "                           (durationsummary['duration']>365*10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LongFlowList = list(LongFlow['StationId'].values)\n",
    "FlowRes = results[(results['StationId'].isin(LongFlowList)) & (results['ResultValue'] != np.nan)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FlowRes.groupby(['Unit']).agg([np.size]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdf = PdfPages(rootname+'flowres_pdf.pdf')\n",
    "\n",
    "for key, grp in FlowRes.groupby(['StationId']):\n",
    "    fig = plt.figure(figsize=(8.27, 11.69), dpi=300)\n",
    "    plt.plot(x=grp['SampleDate'].values,y= grp['ResultValue'].values, label=key)\n",
    "    plt.title(key)\n",
    "    print grp['Unit'][1:1]\n",
    "    plt.ylabel('Discharge')\n",
    "    plt.xlabel('Date')\n",
    "    #plt.legend(loc='best')    \n",
    "    #plt.show()\n",
    "    pdf.savefig(fig)\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot the data so that parameters are now columns.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datap = results.pivot(index='SampleId', columns='ParAbb', values='ResultValue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns from the pivot table that are pretty much empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datap.dropna(subset=['SO4','Cond','Temp','TDS','pH'],how='all',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table lost the `StationId` field when it was pivoted, so now we need to add the `StationId` field back on to the table by joining it to the previous results table using the `SampleId` field.  First we parse down the results table to only the information we want to retain, then we join the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resdrop = ['AnalysisDate', 'AnalytMeth', 'AnalytMethId',\n",
    "             'DetectCond', 'LabComments', 'LabName', 'LimitType',\n",
    "             'MDL', 'MDLUnit', 'MethodDescript',\n",
    "             'OrgId', 'OrgName', 'Param', 'ProjectId',\n",
    "             'QualCode', 'ResultComment', 'ResultStatus', 'ResultValue',\n",
    "             'SampComment', 'SampDepth',\n",
    "             'SampDepthRef', 'SampDepthU', 'SampEquip', 'SampFrac',\n",
    "             'SampMedia', 'SampMeth', 'SampMethName', 'SampType',\n",
    "             'Unit', 'ParAbb']\n",
    "resPivot = results.drop(resdrop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datapiv = pd.merge(datap, resPivot, left_index=True, right_on='SampleId',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a `StationId` field, we can add our station data, but only the data that will be useful for plotting our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pivStats = station.drop(['Aquifer', 'ConstDate', 'Depth', 'DepthUnit',\n",
    "                         'HoleDUnit', 'HoleDepth', 'HorCollMeth', \n",
    "                         'OrgId', 'StationComment', 'StationName', 'matchid'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datapiv = pd.merge(datapiv, pivStats, left_on='StationId', right_index=True,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datapiv.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#datapiv.to_csv(rootname+\"AllResultsPivot.csv\", chunksize=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Create Table For Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "piperdata = datapiv.dropna(subset = ['Ca','Na','Cl','K','Mg','SO4'],how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Relationship between Bicarbonate and Alkalinity.  Fill in missing bicarbonate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "piv = piperdata.ix[:,['Alk','HCO3']]\n",
    "piv = piv[(piv.Alk < 5000)&(piv.HCO3 < 5000)]\n",
    "piv = piv[(piv.Alk > 0)&(piv.HCO3 > 0)]\n",
    "piv.dropna(inplace=True)\n",
    "lin = linregress(piv.Alk.values,piv.HCO3.values)\n",
    "print lin\n",
    "piperdata.ix[:,\"HCO3\"] = piperdata.apply(lambda x: x['Alk']*lin[0]+lin[1] if np.isnan(x['HCO3']) else x['HCO3'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "piperdata = piperdata.drop(['Alk','As','CO2','Cu','DO','NaK','PO4'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "piperdata.dropna(subset=['Lat_Y','HCO3'], how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "StatFreq = piperdata.groupby('StationId')['StationId'].agg([np.count_nonzero]).reset_index()\n",
    "piperdata = pd.merge(piperdata, StatFreq, on='StationId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "piperdata.to_csv(rootname+\"PiperData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#statlump = df.groupby('MonitoringLocationIdentifier').agg([np.mean, np.min, np.max, np.std, np.size, np.median]).reset_index()\n",
    "statlump = datapiv.groupby('StationId').agg([np.median]).reset_index()\n",
    "statlump.dropna(how='any',subset=[('HCO3','median'),('Ca','median')],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datapiv.groupby('FmType')['Temp'].agg([np.min, np.mean, np.median, np.max, np.std, np.size]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datapiv.groupby('FmType')['Cond'].agg([np.min, np.mean, np.median, np.max, np.std, np.size]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datapiv.groupby('FmType')['Cond'].agg([np.min, np.mean, np.median, np.max, np.std, np.size]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "datapiv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\",{'ytick.major.size': '1.0','xtick.major.size': '1.0','axes.grid': False})\n",
    "fms = datapiv[['Cond','FmType']]\n",
    "fms.dropna(inplace=True)\n",
    "fms = fms[fms['Cond'] >= 100.0]\n",
    "fms = fms[fms['Cond'] < 15000.0]\n",
    "fms = fms[~fms['FmType'].isin(['Green River Formation', 'Rock Springs Formation of Mesaverde Group', 'Holocene Alluvium', \n",
    " 'Masuk Member of Mancos Shale', 'Mancos Shale', 'Tununk Shale Member of Mancos Shale', \n",
    " 'Blue Gate Shale Member of Mancos Shale', 'Emery Sandstone Member of Mancos Shale', \n",
    " 'Pleistocene Series', 'Paleozoic Erathem','Ferron Sandstone Member of Mancos Shale'])]\n",
    "\n",
    "#fms.reset_index(inplace=True)\n",
    "#fms.set_index('FmType',inplace=True)\n",
    "#fms.drop(['index'],inplace=True,axis=1)\n",
    "fig = plt.figure()\n",
    "sns.violinplot(vals=fms['Cond'], groupby=fms['FmType'],vert=False, inner='box', bw=.5)\n",
    "fig.savefig(rootname+\"violin.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "datapivcor = datapiv.dropna(subset=['TDS','Q'],how='any')\n",
    "datapivcor = datapivcor[datapivcor['Q']>1]\n",
    "for key, grp in datapivcor.groupby(['StationId']):\n",
    "    with PdfPages(rootname+'multipage_pdf.pdf') as pdf:\n",
    "        if len(grp) > 3:\n",
    "            plt.figure()\n",
    "            plt.scatter(x=grp['Q'],y= grp['TDS'], label=key)\n",
    "            plt.title(key, grp['StationType'])\n",
    "            plt.xlabel('Discharge (cfs)')\n",
    "            plt.ylabel('Total Dissolved Solids (mg/L)')\n",
    "            plt.legend(loc='best')    \n",
    "            plt.show()\n",
    "            pdf.savefig()\n",
    "            plt.close\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?sns.violinplot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
